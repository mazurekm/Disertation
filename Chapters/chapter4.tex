
\chapter{Results}

\section{Experiment environment}
\subsection{Datasets used in trial}

All of the datasets used in the experiment come from \textit{Mulan} project web page. The sizes of sets are differential in order to check behaviours of the algorithms for a small, a middle and a large number of instances. The detailed information about datasets are presented in \cref{tab:exp1}. 

\begin{table}[h]
\centering
\caption{Statistic and details of datasets used in the experiment}
\label{tab:exp1}
    \begin{tabular}{l|c|r|r|r}
    name & domain & instances & features & labels \\ \hline \hline
    enron & text  &  1702  & 1001 &  53 \\
    scene & image &  2407  & 294 & 6 \\   
    yeast & biology & 2417 & 103 & 14 \\
    bibtex & audio & 7395 & 1836 & 159 \\
    corel16k (10 samples) & images & 13811 $\pm$ 87 & 500 & 161 $\pm$ 9\\
    EUR-Lex (directory codes) & text & 19348 & 5000 & 412 \\
    bookmarks & text & 87856 & 2150 & 208
    \end{tabular}
\end{table}

\subsection{Parameters of desktop}

The experiment was performed on one of the available instances (m4.4xlarge) provided by \textit{Amazon Web Services}. It has 64 GB of memory and \textit{Intel Xeon® E5-2676 v3 (Haswell)} processor. Some details connected with CPU can be found in \cref{tab:cpu}. The operating system, used in the experiment, was \textit{Ubuntu 14}.

\begin{table}[h]
\centering
\caption{Extra information about \textit{Intel Xeon® E5-2676 v3 (Haswell)}}
\label{tab:cpu}
    \begin{tabular}{l|l}
    & \\ \hline \hline
    Cache & 20 MB SmartCache \\
    Bus speed & 8 GT/s QPI \\
    Instruction set & 64-bit \\
    Number of cores & 8 \\
    Number of threads & 16 \\
    Processor base frequency & 2.4 GHZ \\
    Intel$^{®}$ Turbo Boost Technology$^{‡}$ & 2.0 \\
    Intel$^{®}$ Turbo vPro Technology$^{‡}$ & yes \\ 
    Intel$^{®}$ Turbo Hyper-Threading Technology$^{‡}$ & yes \\
    Intel$^{®}$ Turbo Virtualization Technology$^{‡}$ & yes
    \end{tabular}
\end{table}

The library was compiled by \textit{GCC 4.9} with the third optimization level (\textit{-O3} flag). The build process certainly takes more time and memory due to inlining functions or loop unrolling etc., however a performance of code is faster. We can find more information about the optimization flags in \textit{GCC} documentation \cite{Opt}. It is also worth mentioning that \textit{OpenBLAS} was used instead of standard \textit{BLAS} \textit{API} in order to enhance the efficency of linear algebra operations and to use the multithreaded environment. 

\section{Comparison of proposed methods}
\subsection{Discussing evaluation metrics}


The quality of the algorithms was measured by the standard metrics, characteristic for the multi-label classification.

\subsubsection{\textit{Precision} and \textit{Recall}} 

\textit{Precision} and \textit{Recall} are very similar measures. \textit{Precision} is a fraction of a number of correct labels to a number of predicted labels, while \textit{Recall} (also called \textit{sensitivity}) is a fraction of a number of correct labels to a number of targets. They can be simply described by the following formulas:  
\begin{equation}
\label{eq:exp2}
\frac{|T \cap P|}{|P|}
\end{equation}
\begin{equation}
\label{eq:exp3}
\frac{|T \cap P|}{|T|}
\end{equation}
where $T$ is a set of targets, while $P$ is a set of predictions. Although their definitions are always the same, they can be computed by three different methods:
\begin{itemize}
\item \textit{Macro-average} - in this method we compute \textit{Precision} and \textit{Recall} for each category of a dataset independently. Finally we take the arithmetic average of these values.
\item \textit{Micro-average} - this method is the most intuitive. We simply sum up true positives, false positives and false negatives for a whole set and then apply them to get the metric. 
\item \textit{Instance-average} - in this approach we compute \textit{Precision} and \textit{Recall} for each instance. In the next step, similarly to \textit{Macro-average}, the arithmetic average is calculated.
\end{itemize}

Unfortunately none of these methods is more significant than the others, so the best way is to use every approach in order to compare the quality of classifiers.  

\subsubsection{\textit{F1 score}}

This metric is simply the harmonic average of \textit{Precision} and \textit{Recall}. Its value is certainly dependent on a chosen method of calculataing \textit{Precision} and \textit{Recall}. As a result, we define \textit{Micro-}, \textit{Macro}, \textit{Instance-average F1 score}. 

\subsubsection{\textit{Hamming loss}}

This metrics can be defined as a fraction of number of wrong labels to a total number of labels. It is described by the following formula:
\begin{equation}
\label{eq:exp1}
    \frac{1}{m}\sum\limits_{i=1}^{m}\frac{\sum\limits_{j=1}^{k}xor(y_{ij}, z_{ij})}{k}
\end{equation}
where $m$ is a number of instances, $k$ is a number of labels, $y_{ij}$ is a target and $z_{ij}$ is a prediction. Let you notice that it is a loss function what means that the better classifier you have, the smaller value you get.  

\subsection{Algorithms quality comparison}

The results of quality experiment are divided into sections - each section is connected with a particular data set. The experiment involves the following algorithms:
\begin{itemize}
    \item CPLST;
    \item LR which stands for linear regression;
    \item LRWithPCA which denotes linear regression with PCA compression on a label space;
    \item LRWithRandomPCA which denotes linear regression with random PCA compression on a label space;
    \item OCCA.
\end{itemize}
All of the tested approaches used a linear regressor with \textit{Tikhonov} regularization - the regularization coefficient was equal to $7.0$. This value was certainly experimentally stated and for different data sets it does not have to be optimal.  

\Crefrange{tab:exp1}{tab:exp7} contain scores of \textit{Micro-}, \textit{Macro-}, \textit{Instance-average F1 score} metrics for particular methods. In case of the algorithms with data compression, an only label space was reduced. The reduction degree was equal to $0.6$ what means that $40\%$ of columns in a transformed space were rejected.
\Crefrange{fig:enron}{fig:bookmarks} show the influence of a reduction degree on a specific metrics. 

\newpage
\subsubsection{Enron dataset}

\begin{table}[H]
\centering
\caption{Quality of classification for enron dataset}
\label{tab:exp1}
\pgfplotstabletypeset [
    col sep=semicolon,
    columns/Method/.style={string type, column type={c|}},
    columns/Macro F1 score/.style={column type={c|}},
    columns/Micro F1 score/.style={column type={c|}},
    columns/Instance F1 score/.style={column type={c|}},
    columns/Hamming loss/.style={column type={c|}},
    every head row/.style={after row=\hline\hline}
]{figures/enron.csv}
\end{table}

\begin{figure}[H]
%\centering
\caption{Quality metrics and reduction degree relation for enron dataset}
\label{fig:enron}

\begin{subfigure}{.5\textwidth}
\caption{Hamming loss and reduction degree relation}
\label{fig:exp1}
\begin{tikzpicture}
    \begin{axis}[legend pos=north east,
        legend style={font=\fontsize{7}{5}\selectfont}, 
        xlabel={Degree of reduction},
        ylabel={Hamming loss},
        width=7cm,
        xmax=1,
        ymax=0.07]
        \addplot table [x=k, y=LRWithPCA, col sep=semicolon] {figures/enron_0.csv};
        \addlegendentry{LRWithPCA}
        \addplot table [x=k, y=CPLST, col sep=semicolon] {figures/enron_0.csv};
        \addlegendentry{CPLST}
        \addplot table [x=k, y=LRWithRandomPCA, col sep=semicolon] {figures/enron_0.csv};
        \addlegendentry{LRWithRandomPCA}
        \addplot table [x=k, y=OCCA, col sep=semicolon] {figures/enron_0.csv};
        \addlegendentry{OCCA}
    \end{axis}
\end{tikzpicture}
\end{subfigure}
\begin{subfigure}{.5\textwidth}
\caption{Macro f1 score and reduction degree relation}
\label{fig:exp2}
\begin{tikzpicture}
    \begin{axis}[legend pos=north east,
        legend style={font=\fontsize{7}{5}\selectfont}, 
        xlabel={Degree of reduction},
        ylabel={Macro F1 score},
        width=7cm,
        xmax=1,
        ymax=0.35]
        \addplot table [x=k, y=LRWithPCA, col sep=semicolon] {figures/enron_1.csv};
        \addlegendentry{LRWithPCA}
        \addplot table [x=k, y=CPLST, col sep=semicolon] {figures/enron_1.csv};
        \addlegendentry{CPLST}
        \addplot table [x=k, y=LRWithRandomPCA, col sep=semicolon] {figures/enron_1.csv};
        \addlegendentry{LRWithRandomPCA}
        \addplot table [x=k, y=OCCA, col sep=semicolon] {figures/enron_1.csv};
        \addlegendentry{OCCA}
    \end{axis}
\end{tikzpicture}
\end{subfigure}

\begin{subfigure}{.5\textwidth}
\caption{Micro f1 score and reduction degree relation}
\label{fig:exp3}
\begin{tikzpicture}
    \begin{axis}[legend pos=north east,
        legend style={font=\fontsize{7}{5}\selectfont}, 
        xlabel={Degree of reduction},
        ylabel={Micro F1 score},
        width=7cm,
        xmax=1,
        ymax=0.6]
        \addplot table [x=k, y=LRWithPCA, col sep=semicolon] {figures/enron_2.csv};
        \addlegendentry{LRWithPCA}
        \addplot table [x=k, y=CPLST, col sep=semicolon] {figures/enron_2.csv};
        \addlegendentry{CPLST}
        \addplot table [x=k, y=LRWithRandomPCA, col sep=semicolon] {figures/enron_2.csv};
        \addlegendentry{LRWithRandomPCA}
        \addplot table [x=k, y=OCCA, col sep=semicolon] {figures/enron_2.csv};
        \addlegendentry{OCCA}
    \end{axis}
\end{tikzpicture}
\end{subfigure}
\begin{subfigure}{.5\textwidth}
\caption{Instance f1 score and reduction degree relation}
\label{fig:exp4}
\begin{tikzpicture}
    \begin{axis}[legend pos=north east,
        legend style={font=\fontsize{7}{5}\selectfont},
        xlabel={Degree of reduction},
        ylabel={Instance f1 score},
        width=7cm,
        xmax=1,
        ymax=0.63]
        \addplot table [x=k, y=LRWithPCA, col sep=semicolon] {figures/enron_3.csv};
        \addlegendentry{LRWithPCA}
        \addplot table [x=k, y=CPLST, col sep=semicolon] {figures/enron_3.csv};
        \addlegendentry{CPLST}
        \addplot table [x=k, y=LRWithRandomPCA, col sep=semicolon] {figures/enron_3.csv};
        \addlegendentry{LRWithRandomPCA}
        \addplot table [x=k, y=OCCA, col sep=semicolon] {figures/enron_3.csv};
        \addlegendentry{OCCA}
    \end{axis}
\end{tikzpicture}
\end{subfigure}


\end{figure}

\subsubsection{Scene dataset}

\begin{table}[H]
\centering
\caption{Quality of classification for scene dataset}
\label{tab:exp2}
\pgfplotstabletypeset [
    col sep=semicolon,
    columns/Method/.style={string type, column type={c|}},
    columns/Macro F1 score/.style={column type={c|}},
    columns/Micro F1 score/.style={column type={c|}},
    columns/Instance F1 score/.style={column type={c|}},
    columns/Hamming loss/.style={column type={c|}},
    every head row/.style={after row=\hline\hline}
]{figures/scene.csv}
\end{table}

\begin{figure}[H]
%\centering
\caption{Quality metrics and reduction degree relation for scene dataset}
\label{fig:scene}

\begin{subfigure}{.5\textwidth}
\caption{Hamming loss and reduction degree relation}
\label{fig:exp5}
\begin{tikzpicture}
    \begin{axis}[legend pos=north east,
        legend style={font=\fontsize{7}{5}\selectfont}, 
        xlabel={Degree of reduction},
        ylabel={Hamming loss},
        width=7cm,
        xmax=1,
        ymax=0.35]
        \addplot table [x=k, y=LRWithPCA, col sep=semicolon] {figures/scene_0.csv};
        \addlegendentry{LRWithPCA}
        \addplot table [x=k, y=CPLST, col sep=semicolon] {figures/scene_0.csv};
        \addlegendentry{CPLST}
        \addplot table [x=k, y=LRWithRandomPCA, col sep=semicolon] {figures/scene_0.csv};
        \addlegendentry{LRWithRandomPCA}
        \addplot table [x=k, y=OCCA, col sep=semicolon] {figures/scene_0.csv};
        \addlegendentry{OCCA}
    \end{axis}
\end{tikzpicture}
\end{subfigure}
\begin{subfigure}{.5\textwidth}
\caption{Macro f1 score and reduction degree relation}
\label{fig:exp6}
\begin{tikzpicture}
    \begin{axis}[legend pos=north east,
        legend style={font=\fontsize{7}{5}\selectfont}, 
        xlabel={Degree of reduction},
        ylabel={Macro F1 score},
        width=7cm,
        xmax=1,
        ymax=1.3]
        \addplot table [x=k, y=LRWithPCA, col sep=semicolon] {figures/scene_1.csv};
        \addlegendentry{LRWithPCA}
        \addplot table [x=k, y=CPLST, col sep=semicolon] {figures/scene_1.csv};
        \addlegendentry{CPLST}
        \addplot table [x=k, y=LRWithRandomPCA, col sep=semicolon] {figures/scene_1.csv};
        \addlegendentry{LRWithRandomPCA}
        \addplot table [x=k, y=OCCA, col sep=semicolon] {figures/scene_1.csv};
        \addlegendentry{OCCA}
    \end{axis}
\end{tikzpicture}
\end{subfigure}

\begin{subfigure}{.5\textwidth}
\caption{Micro f1 score and reduction degree relation}
\label{fig:exp7}
\begin{tikzpicture}
    \begin{axis}[legend pos=north east,
        legend style={font=\fontsize{7}{5}\selectfont}, 
        xlabel={Degree of reduction},
        ylabel={Micro F1 score},
        width=7cm,
        xmax=1,
        ymax=1.3]
        \addplot table [x=k, y=LRWithPCA, col sep=semicolon] {figures/scene_2.csv};
        \addlegendentry{LRWithPCA}
        \addplot table [x=k, y=CPLST, col sep=semicolon] {figures/scene_2.csv};
        \addlegendentry{CPLST}
        \addplot table [x=k, y=LRWithRandomPCA, col sep=semicolon] {figures/scene_2.csv};
        \addlegendentry{LRWithRandomPCA}
        \addplot table [x=k, y=OCCA, col sep=semicolon] {figures/scene_2.csv};
        \addlegendentry{OCCA}
    \end{axis}
\end{tikzpicture}
\end{subfigure}
\begin{subfigure}{.5\textwidth}
\caption{Instance f1 score and reduction degree relation}
\label{fig:exp8}
\begin{tikzpicture}
    \begin{axis}[legend pos=north east,
        legend style={font=\fontsize{7}{5}\selectfont},
        xlabel={Degree of reduction},
        ylabel={Instance f1 score},
        width=7cm,
        xmax=1,
        ymax=1.1]
        \addplot table [x=k, y=LRWithPCA, col sep=semicolon] {figures/scene_3.csv};
        \addlegendentry{LRWithPCA}
        \addplot table [x=k, y=CPLST, col sep=semicolon] {figures/scene_3.csv};
        \addlegendentry{CPLST}
        \addplot table [x=k, y=LRWithRandomPCA, col sep=semicolon] {figures/scene_3.csv};
        \addlegendentry{LRWithRandomPCA}
        \addplot table [x=k, y=OCCA, col sep=semicolon] {figures/scene_3.csv};
        \addlegendentry{OCCA}
    \end{axis}
\end{tikzpicture}
\end{subfigure}


\end{figure}


\subsubsection{Yeast dataset}

\begin{table}[H]
\centering
\caption{Quality of classification for yeast dataset}
\label{tab:exp3}
\pgfplotstabletypeset [
    col sep=semicolon,
    columns/Method/.style={string type, column type={c|}},
    columns/Macro F1 score/.style={column type={c|}},
    columns/Micro F1 score/.style={column type={c|}},
    columns/Instance F1 score/.style={column type={c|}},
    columns/Hamming loss/.style={column type={c|}},
    every head row/.style={after row=\hline\hline}
]{figures/yeast.csv}
\end{table}

\begin{figure}[H]
%\centering
\caption{Quality metrics and reduction degree relation for yeast dataset}
\label{fig:yeast}

\begin{subfigure}{.5\textwidth}
\caption{Hamming loss and reduction degree relation}
\label{fig:exp9}
\begin{tikzpicture}
    \begin{axis}[legend pos=north east,
        legend style={font=\fontsize{7}{5}\selectfont}, 
        xlabel={Degree of reduction},
        ylabel={Hamming loss},
        width=7cm,
        xmax=1,
        ymax=0.25]
        \addplot table [x=k, y=LRWithPCA, col sep=semicolon] {figures/yeast_0.csv};
        \addlegendentry{LRWithPCA}
        \addplot table [x=k, y=CPLST, col sep=semicolon] {figures/yeast_0.csv};
        \addlegendentry{CPLST}
        \addplot table [x=k, y=LRWithRandomPCA, col sep=semicolon] {figures/yeast_0.csv};
        \addlegendentry{LRWithRandomPCA}
        \addplot table [x=k, y=OCCA, col sep=semicolon] {figures/yeast_0.csv};
        \addlegendentry{OCCA}
    \end{axis}
\end{tikzpicture}
\end{subfigure}
\begin{subfigure}{.5\textwidth}
\caption{Macro f1 score and reduction degree relation}
\label{fig:exp10}
\begin{tikzpicture}
    \begin{axis}[legend pos=north east,
        legend style={font=\fontsize{7}{5}\selectfont}, 
        xlabel={Degree of reduction},
        ylabel={Macro F1 score},
        width=7cm,
        xmax=1,
        ymax=0.5]
        \addplot table [x=k, y=LRWithPCA, col sep=semicolon] {figures/yeast_1.csv};
        \addlegendentry{LRWithPCA}
        \addplot table [x=k, y=CPLST, col sep=semicolon] {figures/yeast_1.csv};
        \addlegendentry{CPLST}
        \addplot table [x=k, y=LRWithRandomPCA, col sep=semicolon] {figures/yeast_1.csv};
        \addlegendentry{LRWithRandomPCA}
        \addplot table [x=k, y=OCCA, col sep=semicolon] {figures/yeast_1.csv};
        \addlegendentry{OCCA}
    \end{axis}
\end{tikzpicture}
\end{subfigure}

\begin{subfigure}{.5\textwidth}
\caption{Micro f1 score and reduction degree relation}
\label{fig:exp11}
\begin{tikzpicture}
    \begin{axis}[legend pos=north east,
        legend style={font=\fontsize{7}{5}\selectfont}, 
        xlabel={Degree of reduction},
        ylabel={Micro F1 score},
        width=7cm,
        xmax=1,
        ymax=0.8]
        \addplot table [x=k, y=LRWithPCA, col sep=semicolon] {figures/yeast_2.csv};
        \addlegendentry{LRWithPCA}
        \addplot table [x=k, y=CPLST, col sep=semicolon] {figures/yeast_2.csv};
        \addlegendentry{CPLST}
        \addplot table [x=k, y=LRWithRandomPCA, col sep=semicolon] {figures/yeast_2.csv};
        \addlegendentry{LRWithRandomPCA}
        \addplot table [x=k, y=OCCA, col sep=semicolon] {figures/yeast_2.csv};
        \addlegendentry{OCCA}
    \end{axis}
\end{tikzpicture}
\end{subfigure}
\begin{subfigure}{.5\textwidth}
\caption{Instance f1 score and reduction degree relation}
\label{fig:exp12}
\begin{tikzpicture}
    \begin{axis}[legend pos=north east,
        legend style={font=\fontsize{7}{5}\selectfont},
        xlabel={Degree of reduction},
        ylabel={Instance f1 score},
        width=7cm,
        xmax=1,
        ymax=0.7]
        \addplot table [x=k, y=LRWithPCA, col sep=semicolon] {figures/yeast_3.csv};
        \addlegendentry{LRWithPCA}
        \addplot table [x=k, y=CPLST, col sep=semicolon] {figures/yeast_3.csv};
        \addlegendentry{CPLST}
        \addplot table [x=k, y=LRWithRandomPCA, col sep=semicolon] {figures/yeast_3.csv};
        \addlegendentry{LRWithRandomPCA}
        \addplot table [x=k, y=OCCA, col sep=semicolon] {figures/yeast_3.csv};
        \addlegendentry{OCCA}
    \end{axis}
\end{tikzpicture}
\end{subfigure}

\end{figure}

\subsubsection{Bibtex dataset}

\begin{table}[H]
\centering
\caption{Quality of classification for bibtex dataset}
\label{tab:exp4}
\pgfplotstabletypeset [
    col sep=semicolon,
    columns/Method/.style={string type, column type={c|}},
    columns/Macro F1 score/.style={column type={c|}},
    columns/Micro F1 score/.style={column type={c|}},
    columns/Instance F1 score/.style={column type={c|}},
    columns/Hamming loss/.style={column type={c|}},
    every head row/.style={after row=\hline\hline}
]{figures/bibtex.csv}
\end{table}

\begin{figure}[H]
%\centering
\caption{Quality metrics and reduction degree relation for bibtex dataset}
\label{fig:bibtex}

\begin{subfigure}{.5\textwidth}
\caption{Hamming loss and reduction degree relation}
\label{fig:exp13}
\begin{tikzpicture}
    \begin{axis}[legend pos=north east,
        legend style={font=\fontsize{7}{5}\selectfont}, 
        xlabel={Degree of reduction},
        ylabel={Hamming loss},
        width=7cm,
        xmax=1,
        ymax=0.02]
        \addplot table [x=k, y=LRWithPCA, col sep=semicolon] {figures/bibtex_0.csv};
        \addlegendentry{LRWithPCA}
        \addplot table [x=k, y=CPLST, col sep=semicolon] {figures/bibtex_0.csv};
        \addlegendentry{CPLST}
        \addplot table [x=k, y=LRWithRandomPCA, col sep=semicolon] {figures/bibtex_0.csv};
        \addlegendentry{LRWithRandomPCA}
        \addplot table [x=k, y=OCCA, col sep=semicolon] {figures/bibtex_0.csv};
        \addlegendentry{OCCA}
    \end{axis}
\end{tikzpicture}
\end{subfigure}
\begin{subfigure}{.5\textwidth}
\caption{Macro f1 score and reduction degree relation}
\label{fig:exp14}
\begin{tikzpicture}
    \begin{axis}[legend pos=north east,
        legend style={font=\fontsize{7}{5}\selectfont}, 
        xlabel={Degree of reduction},
        ylabel={Macro F1 score},
        width=7cm,
        xmax=1,
        ymax=0.4]
        \addplot table [x=k, y=LRWithPCA, col sep=semicolon] {figures/bibtex_1.csv};
        \addlegendentry{LRWithPCA}
        \addplot table [x=k, y=CPLST, col sep=semicolon] {figures/bibtex_1.csv};
        \addlegendentry{CPLST}
        \addplot table [x=k, y=LRWithRandomPCA, col sep=semicolon] {figures/bibtex_1.csv};
        \addlegendentry{LRWithRandomPCA}
        \addplot table [x=k, y=OCCA, col sep=semicolon] {figures/bibtex_1.csv};
        \addlegendentry{OCCA}
    \end{axis}
\end{tikzpicture}
\end{subfigure}

\begin{subfigure}{.5\textwidth}
\caption{Micro f1 score and reduction degree relation}
\label{fig:exp15}
\begin{tikzpicture}
    \begin{axis}[legend pos=north east,
        legend style={font=\fontsize{7}{5}\selectfont}, 
        xlabel={Degree of reduction},
        ylabel={Micro F1 score},
        width=7cm,
        xmax=1,
        ymax=0.7]
        \addplot table [x=k, y=LRWithPCA, col sep=semicolon] {figures/bibtex_2.csv};
        \addlegendentry{LRWithPCA}
        \addplot table [x=k, y=CPLST, col sep=semicolon] {figures/bibtex_2.csv};
        \addlegendentry{CPLST}
        \addplot table [x=k, y=LRWithRandomPCA, col sep=semicolon] {figures/bibtex_2.csv};
        \addlegendentry{LRWithRandomPCA}
        \addplot table [x=k, y=OCCA, col sep=semicolon] {figures/bibtex_2.csv};
        \addlegendentry{OCCA}
    \end{axis}
\end{tikzpicture}
\end{subfigure}
\begin{subfigure}{.5\textwidth}
\caption{Instance f1 score and reduction degree relation}
\label{fig:exp16}
\begin{tikzpicture}
    \begin{axis}[legend pos=north east,
        legend style={font=\fontsize{7}{5}\selectfont},
        xlabel={Degree of reduction},
        ylabel={Instance f1 score},
        width=7cm,
        xmax=1,
        ymax=0.6]
        \addplot table [x=k, y=LRWithPCA, col sep=semicolon] {figures/bibtex_3.csv};
        \addlegendentry{LRWithPCA}
        \addplot table [x=k, y=CPLST, col sep=semicolon] {figures/bibtex_3.csv};
        \addlegendentry{CPLST}
        \addplot table [x=k, y=LRWithRandomPCA, col sep=semicolon] {figures/bibtex_3.csv};
        \addlegendentry{LRWithRandomPCA}
        \addplot table [x=k, y=OCCA, col sep=semicolon] {figures/bibtex_3.csv};
        \addlegendentry{OCCA}
    \end{axis}
\end{tikzpicture}
\end{subfigure}


\end{figure}


\subsubsection{Corel16k dataset}

\begin{table}[H]
\centering
\caption{Quality of classification for corel16k dataset}
\label{tab:exp5}
\pgfplotstabletypeset [
    col sep=semicolon,
    columns/Method/.style={string type, column type={c|}},
    columns/Macro F1 score/.style={column type={c|}},
    columns/Micro F1 score/.style={column type={c|}},
    columns/Instance F1 score/.style={column type={c|}},
    columns/Hamming loss/.style={column type={c|}},
    every head row/.style={after row=\hline\hline}
]{figures/Corel16k001.csv}
\end{table}

\begin{figure}[H]
%\centering
\caption{Quality metrics and reduction degree relation for corel16k dataset}
\label{fig:corel16k}

\begin{subfigure}{.5\textwidth}
\caption{Hamming loss and reduction degree relation}
\label{fig:exp17}
\begin{tikzpicture}
    \begin{axis}[legend pos=north east,
        legend style={font=\fontsize{7}{5}\selectfont}, 
        xlabel={Degree of reduction},
        ylabel={Hamming loss},
        width=7cm,
        xmax=1,
        ymax=0.02]
        \addplot table [x=k, y=LRWithPCA, col sep=semicolon] {figures/Corel16k001_0.csv};
        \addlegendentry{LRWithPCA}
        \addplot table [x=k, y=CPLST, col sep=semicolon] {figures/Corel16k001_0.csv};
        \addlegendentry{CPLST}
        \addplot table [x=k, y=LRWithRandomPCA, col sep=semicolon] {figures/Corel16k001_0.csv};
        \addlegendentry{LRWithRandomPCA}
        \addplot table [x=k, y=OCCA, col sep=semicolon] {figures/Corel16k001_0.csv};
        \addlegendentry{OCCA}
    \end{axis}
\end{tikzpicture}
\end{subfigure}
\begin{subfigure}{.5\textwidth}
\caption{Macro f1 score and reduction degree relation}
\label{fig:exp18}
\begin{tikzpicture}
    \begin{axis}[legend pos=north east,
        legend style={font=\fontsize{7}{5}\selectfont}, 
        xlabel={Degree of reduction},
        ylabel={Macro F1 score},
        width=7cm,
        xmax=1,
        ymax=0.05]
        \addplot table [x=k, y=LRWithPCA, col sep=semicolon] {figures/Corel16k001_1.csv};
        \addlegendentry{LRWithPCA}
        \addplot table [x=k, y=CPLST, col sep=semicolon] {figures/Corel16k001_1.csv};
        \addlegendentry{CPLST}
        \addplot table [x=k, y=LRWithRandomPCA, col sep=semicolon] {figures/Corel16k001_1.csv};
        \addlegendentry{LRWithRandomPCA}
        \addplot table [x=k, y=OCCA, col sep=semicolon] {figures/Corel16k001_1.csv};
        \addlegendentry{OCCA}
    \end{axis}
\end{tikzpicture}
\end{subfigure}

\begin{subfigure}{.5\textwidth}
\caption{Micro f1 score and reduction degree relation}
\label{fig:exp19}
\begin{tikzpicture}
    \begin{axis}[legend pos=north east,
        legend style={font=\fontsize{7}{5}\selectfont}, 
        xlabel={Degree of reduction},
        ylabel={Micro F1 score},
        width=7cm,
        xmax=1,
        ymax=0.13]
        \addplot table [x=k, y=LRWithPCA, col sep=semicolon] {figures/Corel16k001_2.csv};
        \addlegendentry{LRWithPCA}
        \addplot table [x=k, y=CPLST, col sep=semicolon] {figures/Corel16k001_2.csv};
        \addlegendentry{CPLST}
        \addplot table [x=k, y=LRWithRandomPCA, col sep=semicolon] {figures/Corel16k001_2.csv};
        \addlegendentry{LRWithRandomPCA}
        \addplot table [x=k, y=OCCA, col sep=semicolon] {figures/Corel16k001_2.csv};
        \addlegendentry{OCCA}
    \end{axis}
\end{tikzpicture}
\end{subfigure}
\begin{subfigure}{.5\textwidth}
\caption{Instance f1 score and reduction degree relation}
\label{fig:exp20}
\begin{tikzpicture}
    \begin{axis}[legend pos=north east,
        legend style={font=\fontsize{7}{5}\selectfont},
        xlabel={Degree of reduction},
        ylabel={Instance f1 score},
        width=7cm,
        xmax=1,
        ymax=0.13]
        \addplot table [x=k, y=LRWithPCA, col sep=semicolon] {figures/Corel16k001_3.csv};
        \addlegendentry{LRWithPCA}
        \addplot table [x=k, y=CPLST, col sep=semicolon] {figures/Corel16k001_3.csv};
        \addlegendentry{CPLST}
        \addplot table [x=k, y=LRWithRandomPCA, col sep=semicolon] {figures/Corel16k001_3.csv};
        \addlegendentry{LRWithRandomPCA}
        \addplot table [x=k, y=OCCA, col sep=semicolon] {figures/Corel16k001_3.csv};
        \addlegendentry{OCCA}
    \end{axis}
\end{tikzpicture}
\end{subfigure}


\end{figure}

\subsubsection{EUR-Lex dataset}

\begin{table}[H]
\centering
\caption{Quality of classification for EUR-Lex dataset}
\label{tab:exp6}
\pgfplotstabletypeset [
    col sep=semicolon,
    columns/Method/.style={string type, column type={c|}},
    columns/Macro F1 score/.style={column type={c|}},
    columns/Micro F1 score/.style={column type={c|}},
    columns/Instance F1 score/.style={column type={c|}},
    columns/Hamming loss/.style={column type={c|}},
    every head row/.style={after row=\hline\hline}
]{figures/eurlex.csv}
\end{table}

\begin{figure}[H]
%\centering
\caption{Quality metrics and reduction degree relation for EUR-Lex dataset}
\label{fig:eurlex}

\begin{subfigure}{.5\textwidth}
\caption{Hamming loss and reduction degree relation}
\label{fig:exp21}
\begin{tikzpicture}
    \begin{axis}[legend pos=north east,
        legend style={font=\fontsize{7}{5}\selectfont}, 
        xlabel={Degree of reduction},
        ylabel={Hamming loss},
        width=7cm,
        xmax=1,
        ymax=0.03]
        \addplot table [x=k, y=LRWithPCA, col sep=semicolon] {figures/eurlex_0.csv};
        \addlegendentry{LRWithPCA}
        \addplot table [x=k, y=CPLST, col sep=semicolon] {figures/eurlex_0.csv};
        \addlegendentry{CPLST}
        \addplot table [x=k, y=LRWithRandomPCA, col sep=semicolon] {figures/eurlex_0.csv};
        \addlegendentry{LRWithRandomPCA}
        \addplot table [x=k, y=OCCA, col sep=semicolon] {figures/eurlex_0.csv};
        \addlegendentry{OCCA}
    \end{axis}
\end{tikzpicture}
\end{subfigure}
\begin{subfigure}{.5\textwidth}
\caption{Macro f1 score and reduction degree relation}
\label{fig:exp22}
\begin{tikzpicture}
    \begin{axis}[legend pos=north east,
        legend style={font=\fontsize{7}{5}\selectfont}, 
        xlabel={Degree of reduction},
        ylabel={Macro F1 score},
        width=7cm,
        xmax=1,
        ymax=0.13]
        \addplot table [x=k, y=LRWithPCA, col sep=semicolon] {figures/eurlex_1.csv};
        \addlegendentry{LRWithPCA}
        \addplot table [x=k, y=CPLST, col sep=semicolon] {figures/eurlex_1.csv};
        \addlegendentry{CPLST}
        \addplot table [x=k, y=LRWithRandomPCA, col sep=semicolon] {figures/eurlex_1.csv};
        \addlegendentry{LRWithRandomPCA}
        \addplot table [x=k, y=OCCA, col sep=semicolon] {figures/eurlex_1.csv};
        \addlegendentry{OCCA}
    \end{axis}
\end{tikzpicture}
\end{subfigure}

\begin{subfigure}{.5\textwidth}
\caption{Micro f1 score and reduction degree relation}
\label{fig:exp23}
\begin{tikzpicture}
    \begin{axis}[legend pos=north east,
        legend style={font=\fontsize{7}{5}\selectfont}, 
        xlabel={Degree of reduction},
        ylabel={Micro F1 score},
        width=7cm,
        xmax=1,
        ymax=0.35]
        \addplot table [x=k, y=LRWithPCA, col sep=semicolon] {figures/eurlex_2.csv};
        \addlegendentry{LRWithPCA}
        \addplot table [x=k, y=CPLST, col sep=semicolon] {figures/eurlex_2.csv};
        \addlegendentry{CPLST}
        \addplot table [x=k, y=LRWithRandomPCA, col sep=semicolon] {figures/eurlex_2.csv};
        \addlegendentry{LRWithRandomPCA}
        \addplot table [x=k, y=OCCA, col sep=semicolon] {figures/eurlex_2.csv};
        \addlegendentry{OCCA}
    \end{axis}
\end{tikzpicture}
\end{subfigure}
\begin{subfigure}{.5\textwidth}
\caption{Instance f1 score and reduction degree relation}
\label{fig:exp24}
\begin{tikzpicture}
    \begin{axis}[legend pos=north east,
        legend style={font=\fontsize{7}{5}\selectfont},
        xlabel={Degree of reduction},
        ylabel={Instance f1 score},
        width=7cm,
        xmax=1,
        ymax=0.6]
        \addplot table [x=k, y=LRWithPCA, col sep=semicolon] {figures/eurlex_3.csv};
        \addlegendentry{LRWithPCA}
        \addplot table [x=k, y=CPLST, col sep=semicolon] {figures/eurlex_3.csv};
        \addlegendentry{CPLST}
        \addplot table [x=k, y=LRWithRandomPCA, col sep=semicolon] {figures/eurlex_3.csv};
        \addlegendentry{LRWithRandomPCA}
        \addplot table [x=k, y=OCCA, col sep=semicolon] {figures/eurlex_3.csv};
        \addlegendentry{OCCA}
    \end{axis}
\end{tikzpicture}
\end{subfigure}


\end{figure}

\subsubsection{Bookmarks dataset}

\begin{table}[H]
\centering
\caption{Quality of classification for bookmarks dataset}
\label{tab:exp7}
\pgfplotstabletypeset [
    col sep=semicolon,
    columns/Method/.style={string type, column type={c|}},
    columns/Macro F1 score/.style={column type={c|}},
    columns/Micro F1 score/.style={column type={c|}},
    columns/Instance F1 score/.style={column type={c|}},
    columns/Hamming loss/.style={column type={c|}},
    every head row/.style={after row=\hline\hline}
]{figures/bookmarks.csv}
\end{table}

\begin{figure}[H]
%\centering
\caption{Quality metrics and reduction degree relation for bookmarks dataset}
\label{fig:bookmarks}

\begin{subfigure}{.5\textwidth}
\caption{Hamming loss and reduction degree relation}
\label{fig:exp25}
\begin{tikzpicture}
    \begin{axis}[legend pos=north east,
        legend style={font=\fontsize{7}{5}\selectfont}, 
        xlabel={Degree of reduction},
        ylabel={Hamming loss},
        width=7cm,
        xmax=1,
        ymax=0.01]
        \addplot table [x=k, y=LRWithPCA, col sep=semicolon] {figures/bookmarks_0.csv};
        \addlegendentry{LRWithPCA}
        \addplot table [x=k, y=CPLST, col sep=semicolon] {figures/bookmarks_0.csv};
        \addlegendentry{CPLST}
        \addplot table [x=k, y=LRWithRandomPCA, col sep=semicolon] {figures/bookmarks_0.csv};
        \addlegendentry{LRWithRandomPCA}
        \addplot table [x=k, y=OCCA, col sep=semicolon] {figures/bookmarks_0.csv};
        \addlegendentry{OCCA}
    \end{axis}
\end{tikzpicture}
\end{subfigure}
\begin{subfigure}{.5\textwidth}
\caption{Macro f1 score and reduction degree relation}
\label{fig:exp26}
\begin{tikzpicture}
    \begin{axis}[legend pos=north east,
        legend style={font=\fontsize{7}{5}\selectfont}, 
        xlabel={Degree of reduction},
        ylabel={Macro F1 score},
        width=7cm,
        xmax=1,
        ymax=0.13]
        \addplot table [x=k, y=LRWithPCA, col sep=semicolon] {figures/bookmarks_1.csv};
        \addlegendentry{LRWithPCA}
        \addplot table [x=k, y=CPLST, col sep=semicolon] {figures/bookmarks_1.csv};
        \addlegendentry{CPLST}
        \addplot table [x=k, y=LRWithRandomPCA, col sep=semicolon] {figures/bookmarks_1.csv};
        \addlegendentry{LRWithRandomPCA}
        \addplot table [x=k, y=OCCA, col sep=semicolon] {figures/bookmarks_1.csv};
        \addlegendentry{OCCA}
    \end{axis}
\end{tikzpicture}
\end{subfigure}

\begin{subfigure}{.5\textwidth}
\caption{Micro f1 score and reduction degree relation}
\label{fig:exp27}
\begin{tikzpicture}
    \begin{axis}[legend pos=north east,
        legend style={font=\fontsize{7}{5}\selectfont}, 
        xlabel={Degree of reduction},
        ylabel={Micro F1 score},
        width=7cm,
        xmax=1,
        ymax=0.25]
        \addplot table [x=k, y=LRWithPCA, col sep=semicolon] {figures/bookmarks_2.csv};
        \addlegendentry{LRWithPCA}
        \addplot table [x=k, y=CPLST, col sep=semicolon] {figures/bookmarks_2.csv};
        \addlegendentry{CPLST}
        \addplot table [x=k, y=LRWithRandomPCA, col sep=semicolon] {figures/bookmarks_2.csv};
        \addlegendentry{LRWithRandomPCA}
        \addplot table [x=k, y=OCCA, col sep=semicolon] {figures/bookmarks_2.csv};
        \addlegendentry{OCCA}
    \end{axis}
\end{tikzpicture}
\end{subfigure}
\begin{subfigure}{.5\textwidth}
\caption{Instance f1 score and reduction degree relation}
\label{fig:exp28}
\begin{tikzpicture}
    \begin{axis}[legend pos=north east,
        legend style={font=\fontsize{7}{5}\selectfont},
        xlabel={Degree of reduction},
        ylabel={Instance f1 score},
        width=7cm,
        xmax=1,
        ymax=0.25]
        \addplot table [x=k, y=LRWithPCA, col sep=semicolon] {figures/bookmarks_3.csv};
        \addlegendentry{LRWithPCA}
        \addplot table [x=k, y=CPLST, col sep=semicolon] {figures/bookmarks_3.csv};
        \addlegendentry{CPLST}
        \addplot table [x=k, y=LRWithRandomPCA, col sep=semicolon] {figures/bookmarks_3.csv};
        \addlegendentry{LRWithRandomPCA}
        \addplot table [x=k, y=OCCA, col sep=semicolon] {figures/bookmarks_3.csv};
        \addlegendentry{OCCA}
    \end{axis}
\end{tikzpicture}
\end{subfigure}


\end{figure}

\newpage
\subsection{Efficency comparison}

The measurement of time of the methods was performed on \textit{bookmarks} data set with a changeable number of instances. The computation was run on sequentially on one core and parallelly on eight cores, in order to show the efficency difference. The experiment involves the following approaches:
\begin{itemize}
    \item CPLST;
    \item LR, which stand for linear regression;
    \item LRWithPCA, which is linear regression with PCA compression on a label space;
    \item LRWithRPCA (1), which is linear regression with random PCA compression on a label space;
    \item LRWithRPCA (2), which is linear regression with random PCA compression on a feature space;
    \item OCCA.
\end{itemize}
Due to meaningful differences (even about an order of magnitude) between particular algorithms, the results are shown in three figures: \ref{fig:exp29} - \ref{fig:exp31}

\newpage
\subsubsection{Performance on one core}

\begin{figure}[H]
\centering
\caption{Time measurement of \textit{LR}, \textit{LRWithRPCA (1)} and \textit{LRWithRPCA(2)} (1 core)}
\label{fig:exp29}
\begin{tikzpicture}[scale=0.93]
    \begin{axis}[legend pos=north east,
        xlabel={number of instances},
        ylabel={time [s]},
        ymax={60}]
        \addplot table [x=instance, y=time, col sep=semicolon] {figures/LR1.csv};
        \addlegendentry{LR}
        \addplot table [x=instance, y=time, col sep=semicolon] {figures/LRWithRandomPCA1.csv};
        \addlegendentry{LRWithRPCA (1)}
        \addplot table [x=instance, y=time, col sep=semicolon] {figures/LRWithRandomPCA_d1.csv};
        \addlegendentry{LRWithRPCA (2)}

    \end{axis}
\end{tikzpicture}
\end{figure}

\begin{figure}[H]
\centering
\caption{Time measurement of \textit{OCCA} and \textit{CPLST} (1 core)}
\label{fig:exp30}
\begin{tikzpicture}[scale=0.93]
    \begin{axis}[legend pos=north east,
        xlabel={number of instances},
        ylabel={time [s]},
        ymax={1500}]
        \addplot table [x=instance, y=time, col sep=semicolon] {figures/CPLST1.csv};
        \addlegendentry{CPLST}
        \addplot table [x=instance, y=time, col sep=semicolon] {figures/OCCA1.csv};
        \addlegendentry{OCCA}

    \end{axis}
\end{tikzpicture}
\end{figure}

\begin{figure}[H]
\centering
\caption{Time measurement of \textit{LRWithPCA} (1 core)}
\label{fig:exp31}
\begin{tikzpicture}[scale=0.93]
    \begin{axis}[legend pos=north east,
        xlabel={number of instances},
        ylabel={time [s]},
        ymax={5000}]
        \addplot table [x=instance, y=time, col sep=semicolon] {figures/LRWithPCA1.csv};
        \addlegendentry{LRWithPCA}

    \end{axis}
\end{tikzpicture}
\end{figure}

\subsubsection{Performance on 8 cores}

\begin{figure}[H]
\centering
\caption{Time measurement of \textit{LR}, \textit{LRWithRPCA(1)} and \textit{LRWithRPCA}(2) (8 cores)}
\label{fig:exp32}
\begin{tikzpicture}[scale=0.93]
    \begin{axis}[legend pos=north east,
        xlabel={number of instances},
        ylabel={time [s]},
        ymax=16]
        \addplot table [x=instance, y=time, col sep=semicolon] {figures/LR.csv};
        \addlegendentry{LR}
        \addplot table [x=instance, y=time, col sep=semicolon] {figures/LRWithRandomPCA.csv};
        \addlegendentry{LRWithRPCA (1)}
        \addplot table [x=instance, y=time, col sep=semicolon] {figures/LRWithRandomPCA_d.csv};
        \addlegendentry{LRWithRPCA (2)}

    \end{axis}
\end{tikzpicture}
\end{figure}

\begin{figure}[H]
\centering
\caption{Time measurement of \textit{OCCA} and \textit{CPLST} (8 cores)}
\label{fig:exp33}
\begin{tikzpicture}[scale=0.93]
    \begin{axis}[legend pos=north east,
        xlabel={number of instances},
        ylabel={time [s]},
        ymax=300]
        \addplot table [x=instance, y=time, col sep=semicolon] {figures/CPLST.csv};
        \addlegendentry{CPLST}
        \addplot table [x=instance, y=time, col sep=semicolon] {figures/OCCA.csv};
        \addlegendentry{OCCA}

    \end{axis}
\end{tikzpicture}
\end{figure}

\begin{figure}[H]
\centering
\caption{Time measurement of \textit{LRWithPCA} (8 cores)}
\label{fig:exp34}
\begin{tikzpicture}[scale=0.93]
    \begin{axis}[legend pos=north east,
        xlabel={number of instances},
        ylabel={time [s]},
        ymax=2500]
        \addplot table [x=instance, y=time, col sep=semicolon] {figures/LRWithPCA.csv};
        \addlegendentry{LRWithPCA}

    \end{axis}
\end{tikzpicture}
\end{figure}


