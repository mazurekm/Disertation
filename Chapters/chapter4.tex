
\chapter{Results}

\section{Experiment environment}
\subsection{Data sets used in experiment}

All of the data sets used in the experiment come from \textit{Mulan} project web page. The sizes of sets are differentiated in order to check behaviours of the algorithms for a low, a medium and a high number of instances. The detailed information about data sets are presented in \Cref{tab:exp1}. 

\begin{table}[h]
\centering
\caption{Statistic and details of data sets used in the experiment}
\label{tab:exp1}
    \begin{tabular}{l|c|r|r|r}
    name & domain & instances & features & labels \\ \hline \hline
    enron & text  &  1702  & 1001 &  53 \\
    scene & image &  2407  & 294 & 6 \\   
    yeast & biology & 2417 & 103 & 14 \\
    bibtex & audio & 7395 & 1836 & 159 \\
    corel16k (10 samples) & images & 13811 $\pm$ 87 & 500 & 161 $\pm$ 9\\
    EUR-Lex (directory codes) & text & 19348 & 5000 & 412 \\
    bookmarks & text & 87856 & 2150 & 208
    \end{tabular}
\end{table}

\subsection{Parameters of desktop}

The experiment was performed on one of the available instances (m4.4xlarge) provided by \textit{Amazon Web Services}. It has 64 GB of memory and \textit{Intel Xeon® E5-2676 v3 (Haswell)} processor. Some details connected with CPU can be found in \Cref{tab:cpu}. The operating system, used in the experiment, was \textit{Ubuntu 14}.

\begin{table}[h]
\centering
\caption{Extra information about Intel Xeon® E5-2676 v3 (Haswell)}
\label{tab:cpu}
    \begin{tabular}{l|l}
    & \\ \hline \hline
    Cache & 20 MB SmartCache \\
    Bus speed & 8 GT/s QPI \\
    Instruction set & 64-bit \\
    Number of cores & 8 \\
    Number of threads & 16 \\
    Processor base frequency & 2.4 GHZ \\
    Intel$^{®}$ Turbo Boost Technology$^{‡}$ & 2.0 \\
    Intel$^{®}$ Turbo vPro Technology$^{‡}$ & yes \\ 
    Intel$^{®}$ Turbo Hyper-Threading Technology$^{‡}$ & yes \\
    Intel$^{®}$ Turbo Virtualization Technology$^{‡}$ & yes
    \end{tabular}
\end{table}

The library was compiled by GCC 4.9 with the third optimization level (\textit{-O3} flag). The build process certainly takes more time and memory due to inlining functions or loop unrolling etc., however a performance of code is faster. We can find more information about the optimization flags in GCC documentation\footnote{\bibentry{Opt}}. It is also worth mentioning that OpenBLAS was used instead of standard BLAS API in order to enhance the efficiency of linear algebra operations and to use multithreading. 

\section{Comparison of proposed methods}
\subsection{Metrics of accuracy}

The accuracy of the algorithms was measured by the standard metrics, characteristic for multi-label classification.

\subsubsection{Precision and recall} 

\textit{Precision} and \textit{recall} are very similar measures. Precision is a fraction of a number of correct labels to a number of predicted labels, while recall (also called \textit{sensitivity}) is a fraction of a number of correct labels to a number of targets. They can be simply described by the following formulas:  
\begin{equation}
\label{eq:exp2}
precision=\frac{|T \cap P|}{|P|}
\end{equation}
\begin{equation}
\label{eq:exp3}
recall=\frac{|T \cap P|}{|T|}
\end{equation}
where $T$ is a set of targets, while $P$ is a set of predictions. Although their definitions are always the same, they can be computed by three different methods:
\begin{itemize}
\item Macro-average - in this method we compute precision and recall for each category independently. Finally we take the arithmetic average of these values.
\item Micro-average - this method is the most intuitive. We simply sum up true positives, false positives and false negatives for a whole set and then apply them to get the metric. 
\item Instance-average - in this approach we compute precision and recall for each instance. In the next step, similarly to Macro-average, the arithmetic average is calculated.
\end{itemize}

Unfortunately none of these methods is more significant than the others, so the best way is to use every approach in order to compare the accuracy of classifiers.  

\subsubsection{F1 score}

This metric is simply the harmonic average of Precision and Recall. Its value is certainly dependent on a chosen method of calculating Precision and Recall. As a result, we define Micro-, Macro-, Instance-average F1 score. 

\subsubsection{Hamming loss}

This metric\footnote{\bibentry{Loss}} can be defined as a fraction of number of wrong labels to a total number of labels. It is described by the following formula:
\begin{equation}
\label{eq:exp1}
    HammingLoss(z_i, y_i)=\frac{1}{m}\sum\limits_{i=1}^{m}\frac{xor(z_i,y_i)}{k}
\end{equation}
where $m$ is a number of instances, $k$ is a number of labels, $y_{i}$ is the ground truth and $z_{i}$ is the prediction. Let you notice that unlike the other metrics, we want Hamming loss to be as low as possible.  

\subsection{Comparison of methods accuracy}

The results of accuracy experiment are divided into sections. Each section is connected with a particular data set. The experiment involves the following algorithms:
\begin{itemize}
    \item CPLST,
    \item LR,
    \item OCCA,
    \item LRWithPCA which denotes linear regression with PCA transformation on a label space,
    \item LRWithRandomPCA which denotes linear regression with randomized PCA compression on a label space.
\end{itemize}
All of the tested approaches used a linear regressor with Tikhonov regularization. The regularization coefficient was equal to $7.0$. This value was certainly stated experimentally and for different data sets it does not have to be optimal.  

\Crefrange{tab:exp1}{tab:exp7} contain scores of Micro-, Macro-, Instance-average F1 score metrics for particular methods. In case of the algorithms with data compression, an only label space was reduced. The reduction degree was equal to $0.6$ what means that $40\%$ of columns in a transformed space were rejected.
\Crefrange{fig:enron}{fig:bookmarks} show the influence of a value of reduction degree on a specific metric. 

\newpage
\subsubsection{Enron data set}

\begin{table}[H]
\centering
\caption{Accuracy of methods for enron data set}
\label{tab:exp1}
\pgfplotstabletypeset [
    col sep=semicolon,
    columns/Method/.style={string type, column type={c|}},
    columns/Macro F1 score/.style={column type={c|}},
    columns/Micro F1 score/.style={column type={c|}},
    columns/Instance F1 score/.style={column type={c|}},
    columns/Hamming loss/.style={column type={c|}},
    every head row/.style={after row=\hline\hline}
]{figures/enron.csv}
\end{table}

\begin{figure}[H]
%\centering
\caption{Relation between reduction degree and accuracy for enron data set}
\label{fig:enron}

\begin{subfigure}{.5\textwidth}
\caption{Hamming loss}
\label{fig:exp1}
\begin{tikzpicture}
    \begin{axis}[legend pos=north east,
        legend style={font=\fontsize{7}{5}\selectfont}, 
        xlabel={Degree of reduction},
        ylabel={Hamming loss},
        width=7cm,
        xmax=1,
        ymax=0.07]
        \addplot table [x=k, y=LRWithPCA, col sep=semicolon] {figures/enron_0.csv};
        \addlegendentry{LRWithPCA}
        \addplot table [x=k, y=CPLST, col sep=semicolon] {figures/enron_0.csv};
        \addlegendentry{CPLST}
        \addplot table [x=k, y=LRWithRandomPCA, col sep=semicolon] {figures/enron_0.csv};
        \addlegendentry{LRWithRandomPCA}
        \addplot table [x=k, y=LR, col sep=semicolon] {figures/enron_0.csv};
        \addlegendentry{OCCA}
        \addplot table [x=k, y=OCCA, col sep=semicolon] {figures/enron_0.csv};
        \addlegendentry{LR}

    \end{axis}
\end{tikzpicture}
\end{subfigure}
\begin{subfigure}{.5\textwidth}
\caption{Macro F1 score}
\label{fig:exp2}
\begin{tikzpicture}
    \begin{axis}[legend pos=north east,
        legend style={font=\fontsize{7}{5}\selectfont}, 
        xlabel={Degree of reduction},
        ylabel={Macro F1 score},
        width=7cm,
        xmax=1,
        ymax=0.35]
        \addplot table [x=k, y=LRWithPCA, col sep=semicolon] {figures/enron_1.csv};
        \addlegendentry{LRWithPCA}
        \addplot table [x=k, y=CPLST, col sep=semicolon] {figures/enron_1.csv};
        \addlegendentry{CPLST}
        \addplot table [x=k, y=LRWithRandomPCA, col sep=semicolon] {figures/enron_1.csv};
        \addlegendentry{LRWithRandomPCA}
        \addplot table [x=k, y=OCCA, col sep=semicolon] {figures/enron_1.csv};
        \addlegendentry{OCCA}
        \addplot table [x=k, y=LR, col sep=semicolon] {figures/enron_1.csv};
        \addlegendentry{LR}

    \end{axis}
\end{tikzpicture}
\end{subfigure}

\begin{subfigure}{.5\textwidth}
\caption{Micro F1 score}
\label{fig:exp3}
\begin{tikzpicture}
    \begin{axis}[legend pos=north east,
        legend style={font=\fontsize{7}{5}\selectfont}, 
        xlabel={Degree of reduction},
        ylabel={Micro F1 score},
        width=7cm,
        xmax=1,
        ymax=0.65]
        \addplot table [x=k, y=LRWithPCA, col sep=semicolon] {figures/enron_2.csv};
        \addlegendentry{LRWithPCA}
        \addplot table [x=k, y=CPLST, col sep=semicolon] {figures/enron_2.csv};
        \addlegendentry{CPLST}
        \addplot table [x=k, y=LRWithRandomPCA, col sep=semicolon] {figures/enron_2.csv};
        \addlegendentry{LRWithRandomPCA}
        \addplot table [x=k, y=OCCA, col sep=semicolon] {figures/enron_2.csv};
        \addlegendentry{OCCA}
        \addplot table [x=k, y=LR, col sep=semicolon] {figures/enron_2.csv};
        \addlegendentry{LR}

    \end{axis}
\end{tikzpicture}
\end{subfigure}
\begin{subfigure}{.5\textwidth}
\caption{Instance F1 score}
\label{fig:exp4}
\begin{tikzpicture}
    \begin{axis}[legend pos=north east,
        legend style={font=\fontsize{7}{5}\selectfont},
        xlabel={Degree of reduction},
        ylabel={Instance F1 score},
        width=7cm,
        xmax=1,
        ymax=0.7]
        \addplot table [x=k, y=LRWithPCA, col sep=semicolon] {figures/enron_3.csv};
        \addlegendentry{LRWithPCA}
        \addplot table [x=k, y=CPLST, col sep=semicolon] {figures/enron_3.csv};
        \addlegendentry{CPLST}
        \addplot table [x=k, y=LRWithRandomPCA, col sep=semicolon] {figures/enron_3.csv};
        \addlegendentry{LRWithRandomPCA}
        \addplot table [x=k, y=OCCA, col sep=semicolon] {figures/enron_3.csv};
        \addlegendentry{OCCA}
        \addplot table [x=k, y=LR, col sep=semicolon] {figures/enron_3.csv};
        \addlegendentry{LR}
    \end{axis}
\end{tikzpicture}
\end{subfigure}

\end{figure}

\subsubsection{Scene data set}

\begin{table}[H]
\centering
\caption{Accuracy of methods for scene data set}
\label{tab:exp2}
\pgfplotstabletypeset [
    col sep=semicolon,
    columns/Method/.style={string type, column type={c|}},
    columns/Macro F1 score/.style={column type={c|}},
    columns/Micro F1 score/.style={column type={c|}},
    columns/Instance F1 score/.style={column type={c|}},
    columns/Hamming loss/.style={column type={c|}},
    every head row/.style={after row=\hline\hline}
]{figures/scene.csv}
\end{table}

\begin{figure}[H]
%\centering
\caption{Relation between reduction degree and accuracy for scene data set}
\label{fig:scene}

\begin{subfigure}{.5\textwidth}
\caption{Hamming loss}
\label{fig:exp5}
\begin{tikzpicture}
    \begin{axis}[legend pos=north east,
        legend style={font=\fontsize{7}{5}\selectfont}, 
        xlabel={Degree of reduction},
        ylabel={Hamming loss},
        width=7cm,
        xmax=1,
        ymax=0.35]
        \addplot table [x=k, y=LRWithPCA, col sep=semicolon] {figures/scene_0.csv};
        \addlegendentry{LRWithPCA}
        \addplot table [x=k, y=CPLST, col sep=semicolon] {figures/scene_0.csv};
        \addlegendentry{CPLST}
        \addplot table [x=k, y=LRWithRandomPCA, col sep=semicolon] {figures/scene_0.csv};
        \addlegendentry{LRWithRandomPCA}
        \addplot table [x=k, y=OCCA, col sep=semicolon] {figures/scene_0.csv};
        \addlegendentry{OCCA}
        \addplot table [x=k, y=LR, col sep=semicolon] {figures/scene_0.csv};
        \addlegendentry{LR}
    \end{axis}
\end{tikzpicture}
\end{subfigure}
\begin{subfigure}{.5\textwidth}
\caption{Macro F1 score}
\label{fig:exp6}
\begin{tikzpicture}
    \begin{axis}[legend pos=north east,
        legend style={font=\fontsize{7}{5}\selectfont}, 
        xlabel={Degree of reduction},
        ylabel={Macro F1 score},
        width=7cm,
        xmax=1,
        ymax=1.5]
        \addplot table [x=k, y=LRWithPCA, col sep=semicolon] {figures/scene_1.csv};
        \addlegendentry{LRWithPCA}
        \addplot table [x=k, y=CPLST, col sep=semicolon] {figures/scene_1.csv};
        \addlegendentry{CPLST}
        \addplot table [x=k, y=LRWithRandomPCA, col sep=semicolon] {figures/scene_1.csv};
        \addlegendentry{LRWithRandomPCA}
        \addplot table [x=k, y=OCCA, col sep=semicolon] {figures/scene_1.csv};
        \addlegendentry{OCCA}
        \addplot table [x=k, y=LR, col sep=semicolon] {figures/scene_1.csv};
        \addlegendentry{LR}
    \end{axis}
\end{tikzpicture}
\end{subfigure}

\begin{subfigure}{.5\textwidth}
\caption{Micro F1 score}
\label{fig:exp7}
\begin{tikzpicture}
    \begin{axis}[legend pos=north east,
        legend style={font=\fontsize{7}{5}\selectfont}, 
        xlabel={Degree of reduction},
        ylabel={Micro F1 score},
        width=7cm,
        xmax=1,
        ymax=1.5]
        \addplot table [x=k, y=LRWithPCA, col sep=semicolon] {figures/scene_2.csv};
        \addlegendentry{LRWithPCA}
        \addplot table [x=k, y=CPLST, col sep=semicolon] {figures/scene_2.csv};
        \addlegendentry{CPLST}
        \addplot table [x=k, y=LRWithRandomPCA, col sep=semicolon] {figures/scene_2.csv};
        \addlegendentry{LRWithRandomPCA}
        \addplot table [x=k, y=OCCA, col sep=semicolon] {figures/scene_2.csv};
        \addlegendentry{OCCA}
        \addplot table [x=k, y=LR, col sep=semicolon] {figures/scene_2.csv};
        \addlegendentry{LR}
    \end{axis}
\end{tikzpicture}
\end{subfigure}
\begin{subfigure}{.5\textwidth}
\caption{Instance F1 score}
\label{fig:exp8}
\begin{tikzpicture}
    \begin{axis}[legend pos=north east,
        legend style={font=\fontsize{7}{5}\selectfont},
        xlabel={Degree of reduction},
        ylabel={Instance F1 score},
        width=7cm,
        xmax=1,
        ymax=1.3]
        \addplot table [x=k, y=LRWithPCA, col sep=semicolon] {figures/scene_3.csv};
        \addlegendentry{LRWithPCA}
        \addplot table [x=k, y=CPLST, col sep=semicolon] {figures/scene_3.csv};
        \addlegendentry{CPLST}
        \addplot table [x=k, y=LRWithRandomPCA, col sep=semicolon] {figures/scene_3.csv};
        \addlegendentry{LRWithRandomPCA}
        \addplot table [x=k, y=OCCA, col sep=semicolon] {figures/scene_3.csv};
        \addlegendentry{OCCA}
        \addplot table [x=k, y=LR, col sep=semicolon] {figures/scene_3.csv};
        \addlegendentry{LR}
    \end{axis}
\end{tikzpicture}
\end{subfigure}


\end{figure}


\subsubsection{Yeast data set}

\begin{table}[H]
\centering
\caption{Accuracy of methods for yeast data set}
\label{tab:exp3}
\pgfplotstabletypeset [
    col sep=semicolon,
    columns/Method/.style={string type, column type={c|}},
    columns/Macro F1 score/.style={column type={c|}},
    columns/Micro F1 score/.style={column type={c|}},
    columns/Instance F1 score/.style={column type={c|}},
    columns/Hamming loss/.style={column type={c|}},
    every head row/.style={after row=\hline\hline}
]{figures/yeast.csv}
\end{table}

\begin{figure}[H]
%\centering
\caption{Relation between reduction degree and accuracy for yeast data set}
\label{fig:yeast}

\begin{subfigure}{.5\textwidth}
\caption{Hamming loss}
\label{fig:exp9}
\begin{tikzpicture}
    \begin{axis}[legend pos=north east,
        legend style={font=\fontsize{7}{5}\selectfont}, 
        xlabel={Degree of reduction},
        ylabel={Hamming loss},
        width=7cm,
        xmax=1,
        ymax=0.25]
        \addplot table [x=k, y=LRWithPCA, col sep=semicolon] {figures/yeast_0.csv};
        \addlegendentry{LRWithPCA}
        \addplot table [x=k, y=CPLST, col sep=semicolon] {figures/yeast_0.csv};
        \addlegendentry{CPLST}
        \addplot table [x=k, y=LRWithRandomPCA, col sep=semicolon] {figures/yeast_0.csv};
        \addlegendentry{LRWithRandomPCA}
        \addplot table [x=k, y=OCCA, col sep=semicolon] {figures/yeast_0.csv};
        \addlegendentry{OCCA}
        \addplot table [x=k, y=LR, col sep=semicolon] {figures/yeast_0.csv};
        \addlegendentry{LR}
    \end{axis}
\end{tikzpicture}
\end{subfigure}
\begin{subfigure}{.5\textwidth}
\caption{Macro F1 score}
\label{fig:exp10}
\begin{tikzpicture}
    \begin{axis}[legend pos=north east,
        legend style={font=\fontsize{7}{5}\selectfont}, 
        xlabel={Degree of reduction},
        ylabel={Macro F1 score},
        width=7cm,
        xmax=1,
        ymax=0.5]
        \addplot table [x=k, y=LRWithPCA, col sep=semicolon] {figures/yeast_1.csv};
        \addlegendentry{LRWithPCA}
        \addplot table [x=k, y=CPLST, col sep=semicolon] {figures/yeast_1.csv};
        \addlegendentry{CPLST}
        \addplot table [x=k, y=LRWithRandomPCA, col sep=semicolon] {figures/yeast_1.csv};
        \addlegendentry{LRWithRandomPCA}
        \addplot table [x=k, y=OCCA, col sep=semicolon] {figures/yeast_1.csv};
        \addlegendentry{OCCA}
        \addplot table [x=k, y=LR, col sep=semicolon] {figures/yeast_1.csv};
        \addlegendentry{LR}
    \end{axis}
\end{tikzpicture}
\end{subfigure}

\begin{subfigure}{.5\textwidth}
\caption{Micro F1 score}
\label{fig:exp11}
\begin{tikzpicture}
    \begin{axis}[legend pos=north east,
        legend style={font=\fontsize{7}{5}\selectfont}, 
        xlabel={Degree of reduction},
        ylabel={Micro F1 score},
        width=7cm,
        xmax=1,
        ymax=0.8]
        \addplot table [x=k, y=LRWithPCA, col sep=semicolon] {figures/yeast_2.csv};
        \addlegendentry{LRWithPCA}
        \addplot table [x=k, y=CPLST, col sep=semicolon] {figures/yeast_2.csv};
        \addlegendentry{CPLST}
        \addplot table [x=k, y=LRWithRandomPCA, col sep=semicolon] {figures/yeast_2.csv};
        \addlegendentry{LRWithRandomPCA}
        \addplot table [x=k, y=OCCA, col sep=semicolon] {figures/yeast_2.csv};
        \addlegendentry{OCCA}
        \addplot table [x=k, y=LR, col sep=semicolon] {figures/yeast_2.csv};
        \addlegendentry{LR}
    \end{axis}
\end{tikzpicture}
\end{subfigure}
\begin{subfigure}{.5\textwidth}
\caption{Instance F1 score}
\label{fig:exp12}
\begin{tikzpicture}
    \begin{axis}[legend pos=north east,
        legend style={font=\fontsize{7}{5}\selectfont},
        xlabel={Degree of reduction},
        ylabel={Instance F1 score},
        width=7cm,
        xmax=1,
        ymax=0.8]
        \addplot table [x=k, y=LRWithPCA, col sep=semicolon] {figures/yeast_3.csv};
        \addlegendentry{LRWithPCA}
        \addplot table [x=k, y=CPLST, col sep=semicolon] {figures/yeast_3.csv};
        \addlegendentry{CPLST}
        \addplot table [x=k, y=LRWithRandomPCA, col sep=semicolon] {figures/yeast_3.csv};
        \addlegendentry{LRWithRandomPCA}
        \addplot table [x=k, y=OCCA, col sep=semicolon] {figures/yeast_3.csv};
        \addlegendentry{OCCA}
        \addplot table [x=k, y=LR, col sep=semicolon] {figures/yeast_3.csv};
        \addlegendentry{LR}
    \end{axis}
\end{tikzpicture}
\end{subfigure}

\end{figure}

\subsubsection{Bibtex data set}

\begin{table}[H]
\centering
\caption{Accuracy of methods for bibtex data set}
\label{tab:exp4}
\pgfplotstabletypeset [
    col sep=semicolon,
    columns/Method/.style={string type, column type={c|}},
    columns/Macro F1 score/.style={column type={c|}},
    columns/Micro F1 score/.style={column type={c|}},
    columns/Instance F1 score/.style={column type={c|}},
    columns/Hamming loss/.style={column type={c|}},
    every head row/.style={after row=\hline\hline}
]{figures/bibtex.csv}
\end{table}

\begin{figure}[H]
%\centering
\caption{Relation between reduction degree and accuracy for bibtex data set}
\label{fig:bibtex}

\begin{subfigure}{.5\textwidth}
\caption{Hamming loss}
\label{fig:exp13}
\begin{tikzpicture}
    \begin{axis}[legend pos=north east,
        legend style={font=\fontsize{7}{5}\selectfont}, 
        xlabel={Degree of reduction},
        ylabel={Hamming loss},
        width=7cm,
        xmax=1,
        ymax=0.02]
        \addplot table [x=k, y=LRWithPCA, col sep=semicolon] {figures/bibtex_0.csv};
        \addlegendentry{LRWithPCA}
        \addplot table [x=k, y=CPLST, col sep=semicolon] {figures/bibtex_0.csv};
        \addlegendentry{CPLST}
        \addplot table [x=k, y=LRWithRandomPCA, col sep=semicolon] {figures/bibtex_0.csv};
        \addlegendentry{LRWithRandomPCA}
        \addplot table [x=k, y=OCCA, col sep=semicolon] {figures/bibtex_0.csv};
        \addlegendentry{OCCA}
        \addplot table [x=k, y=LR, col sep=semicolon] {figures/bibtex_0.csv};
        \addlegendentry{LR}
    \end{axis}
\end{tikzpicture}
\end{subfigure}
\begin{subfigure}{.5\textwidth}
\caption{Macro F1 score}
\label{fig:exp14}
\begin{tikzpicture}
    \begin{axis}[legend pos=north east,
        legend style={font=\fontsize{7}{5}\selectfont}, 
        xlabel={Degree of reduction},
        ylabel={Macro F1 score},
        width=7cm,
        xmax=1,
        ymax=0.45]
        \addplot table [x=k, y=LRWithPCA, col sep=semicolon] {figures/bibtex_1.csv};
        \addlegendentry{LRWithPCA}
        \addplot table [x=k, y=CPLST, col sep=semicolon] {figures/bibtex_1.csv};
        \addlegendentry{CPLST}
        \addplot table [x=k, y=LRWithRandomPCA, col sep=semicolon] {figures/bibtex_1.csv};
        \addlegendentry{LRWithRandomPCA}
        \addplot table [x=k, y=OCCA, col sep=semicolon] {figures/bibtex_1.csv};
        \addlegendentry{OCCA}
        \addplot table [x=k, y=LR, col sep=semicolon] {figures/bibtex_1.csv};
        \addlegendentry{LR}
    \end{axis}
\end{tikzpicture}
\end{subfigure}

\begin{subfigure}{.5\textwidth}
\caption{Micro F1 score}
\label{fig:exp15}
\begin{tikzpicture}
    \begin{axis}[legend pos=north east,
        legend style={font=\fontsize{7}{5}\selectfont}, 
        xlabel={Degree of reduction},
        ylabel={Micro F1 score},
        width=7cm,
        xmax=1,
        ymax=0.75]
        \addplot table [x=k, y=LRWithPCA, col sep=semicolon] {figures/bibtex_2.csv};
        \addlegendentry{LRWithPCA}
        \addplot table [x=k, y=CPLST, col sep=semicolon] {figures/bibtex_2.csv};
        \addlegendentry{CPLST}
        \addplot table [x=k, y=LRWithRandomPCA, col sep=semicolon] {figures/bibtex_2.csv};
        \addlegendentry{LRWithRandomPCA}
        \addplot table [x=k, y=OCCA, col sep=semicolon] {figures/bibtex_2.csv};
        \addlegendentry{OCCA}
        \addplot table [x=k, y=LR, col sep=semicolon] {figures/bibtex_2.csv};
        \addlegendentry{LR}
    \end{axis}
\end{tikzpicture}
\end{subfigure}
\begin{subfigure}{.5\textwidth}
\caption{Instance F1 score}
\label{fig:exp16}
\begin{tikzpicture}
    \begin{axis}[legend pos=north east,
        legend style={font=\fontsize{7}{5}\selectfont},
        xlabel={Degree of reduction},
        ylabel={Instance F1 score},
        width=7cm,
        xmax=1,
        ymax=0.65]
        \addplot table [x=k, y=LRWithPCA, col sep=semicolon] {figures/bibtex_3.csv};
        \addlegendentry{LRWithPCA}
        \addplot table [x=k, y=CPLST, col sep=semicolon] {figures/bibtex_3.csv};
        \addlegendentry{CPLST}
        \addplot table [x=k, y=LRWithRandomPCA, col sep=semicolon] {figures/bibtex_3.csv};
        \addlegendentry{LRWithRandomPCA}
        \addplot table [x=k, y=OCCA, col sep=semicolon] {figures/bibtex_3.csv};
        \addlegendentry{OCCA}
        \addplot table [x=k, y=LR, col sep=semicolon] {figures/bibtex_3.csv};
        \addlegendentry{LR}
    \end{axis}
\end{tikzpicture}
\end{subfigure}


\end{figure}


\subsubsection{Corel16k data set}

\begin{table}[H]
\centering
\caption{Accuracy of methods for corel16k data set}
\label{tab:exp5}
\pgfplotstabletypeset [
    col sep=semicolon,
    columns/Method/.style={string type, column type={c|}},
    columns/Macro F1 score/.style={column type={c|}},
    columns/Micro F1 score/.style={column type={c|}},
    columns/Instance F1 score/.style={column type={c|}},
    columns/Hamming loss/.style={column type={c|}},
    every head row/.style={after row=\hline\hline}
]{figures/Corel16k001.csv}
\end{table}

\begin{figure}[H]
%\centering
\caption{Relation between reduction degree and accuracy for corel16k data set}
\label{fig:corel16k}

\begin{subfigure}{.5\textwidth}
\caption{Hamming loss}
\label{fig:exp17}
\begin{tikzpicture}
    \begin{axis}[legend pos=north east,
        legend style={font=\fontsize{7}{5}\selectfont}, 
        xlabel={Degree of reduction},
        ylabel={Hamming loss},
        width=7cm,
        xmax=1,
        ymax=0.02]
        \addplot table [x=k, y=LRWithPCA, col sep=semicolon] {figures/Corel16k001_0.csv};
        \addlegendentry{LRWithPCA}
        \addplot table [x=k, y=CPLST, col sep=semicolon] {figures/Corel16k001_0.csv};
        \addlegendentry{CPLST}
        \addplot table [x=k, y=LRWithRandomPCA, col sep=semicolon] {figures/Corel16k001_0.csv};
        \addlegendentry{LRWithRandomPCA}
        \addplot table [x=k, y=OCCA, col sep=semicolon] {figures/Corel16k001_0.csv};
        \addlegendentry{OCCA}
        \addplot table [x=k, y=LR, col sep=semicolon] {figures/Corel16k001_0.csv};
        \addlegendentry{LR}
    \end{axis}
\end{tikzpicture}
\end{subfigure}
\begin{subfigure}{.5\textwidth}
\caption{Macro F1 score}
\label{fig:exp18}
\begin{tikzpicture}
    \begin{axis}[legend pos=north east,
        legend style={font=\fontsize{7}{5}\selectfont}, 
        xlabel={Degree of reduction},
        ylabel={Macro F1 score},
        width=7cm,
        xmax=1,
        ymax=0.05]
        \addplot table [x=k, y=LRWithPCA, col sep=semicolon] {figures/Corel16k001_1.csv};
        \addlegendentry{LRWithPCA}
        \addplot table [x=k, y=CPLST, col sep=semicolon] {figures/Corel16k001_1.csv};
        \addlegendentry{CPLST}
        \addplot table [x=k, y=LRWithRandomPCA, col sep=semicolon] {figures/Corel16k001_1.csv};
        \addlegendentry{LRWithRandomPCA}
        \addplot table [x=k, y=OCCA, col sep=semicolon] {figures/Corel16k001_1.csv};
        \addlegendentry{OCCA}
        \addplot table [x=k, y=LR, col sep=semicolon] {figures/Corel16k001_1.csv};
        \addlegendentry{LR}
    \end{axis}
\end{tikzpicture}
\end{subfigure}

\begin{subfigure}{.5\textwidth}
\caption{Micro F1 score}
\label{fig:exp19}
\begin{tikzpicture}
    \begin{axis}[legend pos=north east,
        legend style={font=\fontsize{7}{5}\selectfont}, 
        xlabel={Degree of reduction},
        ylabel={Micro F1 score},
        ylabel style={yshift=0.4cm},
        width=7cm,
        xmax=1,
        ymax=0.15]
        \addplot table [x=k, y=LRWithPCA, col sep=semicolon] {figures/Corel16k001_2.csv};
        \addlegendentry{LRWithPCA}
        \addplot table [x=k, y=CPLST, col sep=semicolon] {figures/Corel16k001_2.csv};
        \addlegendentry{CPLST}
        \addplot table [x=k, y=LRWithRandomPCA, col sep=semicolon] {figures/Corel16k001_2.csv};
        \addlegendentry{LRWithRandomPCA}
        \addplot table [x=k, y=OCCA, col sep=semicolon] {figures/Corel16k001_2.csv};
        \addlegendentry{OCCA}
        \addplot table [x=k, y=LR, col sep=semicolon] {figures/Corel16k001_2.csv};
        \addlegendentry{LR}
    \end{axis}
\end{tikzpicture}
\end{subfigure}
\begin{subfigure}{.5\textwidth}
\caption{Instance F1 score}
\label{fig:exp20}
\begin{tikzpicture}
    \begin{axis}[legend pos=north east,
        legend style={font=\fontsize{7}{5}\selectfont},
        xlabel={Degree of reduction},
        ylabel={Instance F1 score},
        ylabel style={yshift=0.4cm},
        width=7cm,
        xmax=1,
        ymax=0.13]
        \addplot table [x=k, y=LRWithPCA, col sep=semicolon] {figures/Corel16k001_3.csv};
        \addlegendentry{LRWithPCA}
        \addplot table [x=k, y=CPLST, col sep=semicolon] {figures/Corel16k001_3.csv};
        \addlegendentry{CPLST}
        \addplot table [x=k, y=LRWithRandomPCA, col sep=semicolon] {figures/Corel16k001_3.csv};
        \addlegendentry{LRWithRandomPCA}
        \addplot table [x=k, y=OCCA, col sep=semicolon] {figures/Corel16k001_3.csv};
        \addlegendentry{OCCA}
        \addplot table [x=k, y=LR, col sep=semicolon] {figures/Corel16k001_3.csv};
        \addlegendentry{LR}
    \end{axis}
\end{tikzpicture}
\end{subfigure}


\end{figure}

\subsubsection{EUR-Lex data set}

\begin{table}[H]
\centering
\caption{Accuracy of methods for EUR-Lex data set}
\label{tab:exp6}
\pgfplotstabletypeset [
    col sep=semicolon,
    columns/Method/.style={string type, column type={c|}},
    columns/Macro F1 score/.style={column type={c|}},
    columns/Micro F1 score/.style={column type={c|}},
    columns/Instance F1 score/.style={column type={c|}},
    columns/Hamming loss/.style={column type={c|}},
    every head row/.style={after row=\hline\hline}
]{figures/eurlex.csv}
\end{table}

\begin{figure}[H]
%\centering
\caption{Relation between reduction degree and accuracy for EUR-Lex data set}
\label{fig:eurlex}

\begin{subfigure}{.5\textwidth}
\caption{Hamming loss}
\label{fig:exp21}
\begin{tikzpicture}
    \begin{axis}[legend pos=north east,
        legend style={font=\fontsize{7}{5}\selectfont}, 
        xlabel={Degree of reduction},
        ylabel={Hamming loss},
        width=7cm,
        xmax=1,
        ymax=0.05]
        \addplot table [x=k, y=LRWithPCA, col sep=semicolon] {figures/eurlex_0.csv};
        \addlegendentry{LRWithPCA}
        \addplot table [x=k, y=CPLST, col sep=semicolon] {figures/eurlex_0.csv};
        \addlegendentry{CPLST}
        \addplot table [x=k, y=LRWithRandomPCA, col sep=semicolon] {figures/eurlex_0.csv};
        \addlegendentry{LRWithRandomPCA}
        \addplot table [x=k, y=OCCA, col sep=semicolon] {figures/eurlex_0.csv};
        \addlegendentry{OCCA}
        \addplot table [x=k, y=LR, col sep=semicolon] {figures/eurlex_0.csv};
        \addlegendentry{LR}
    \end{axis}
\end{tikzpicture}
\end{subfigure}
\begin{subfigure}{.5\textwidth}
\caption{Macro F1 score}
\label{fig:exp22}
\begin{tikzpicture}
    \begin{axis}[legend pos=north east,
        legend style={font=\fontsize{7}{5}\selectfont}, 
        xlabel={Degree of reduction},
        ylabel={Macro F1 score},
        ylabel style={yshift=0.4cm},
        width=7cm,
        xmax=1,
        ymax=0.15]
        \addplot table [x=k, y=LRWithPCA, col sep=semicolon] {figures/eurlex_1.csv};
        \addlegendentry{LRWithPCA}
        \addplot table [x=k, y=CPLST, col sep=semicolon] {figures/eurlex_1.csv};
        \addlegendentry{CPLST}
        \addplot table [x=k, y=LRWithRandomPCA, col sep=semicolon] {figures/eurlex_1.csv};
        \addlegendentry{LRWithRandomPCA}
        \addplot table [x=k, y=OCCA, col sep=semicolon] {figures/eurlex_1.csv};
        \addlegendentry{OCCA}
        \addplot table [x=k, y=LR, col sep=semicolon] {figures/eurlex_1.csv};
        \addlegendentry{LR}
    \end{axis}
\end{tikzpicture}
\end{subfigure}

\begin{subfigure}{.5\textwidth}
\caption{Micro F1 score}
\label{fig:exp23}
\begin{tikzpicture}
    \begin{axis}[legend pos=north east,
        legend style={font=\fontsize{7}{5}\selectfont}, 
        xlabel={Degree of reduction},
        ylabel={Micro F1 score},
        width=7cm,
        xmax=1,
        ymax=0.4]
        \addplot table [x=k, y=LRWithPCA, col sep=semicolon] {figures/eurlex_2.csv};
        \addlegendentry{LRWithPCA}
        \addplot table [x=k, y=CPLST, col sep=semicolon] {figures/eurlex_2.csv};
        \addlegendentry{CPLST}
        \addplot table [x=k, y=LRWithRandomPCA, col sep=semicolon] {figures/eurlex_2.csv};
        \addlegendentry{LRWithRandomPCA}
        \addplot table [x=k, y=OCCA, col sep=semicolon] {figures/eurlex_2.csv};
        \addlegendentry{OCCA}
        \addplot table [x=k, y=LR, col sep=semicolon] {figures/eurlex_2.csv};
        \addlegendentry{LR}
    \end{axis}
\end{tikzpicture}
\end{subfigure}
\begin{subfigure}{.5\textwidth}
\caption{Instance F1 score}
\label{fig:exp24}
\begin{tikzpicture}
    \begin{axis}[legend pos=north east,
        legend style={font=\fontsize{7}{5}\selectfont},
        xlabel={Degree of reduction},
        ylabel={Instance F1 score},
        width=7cm,
        xmax=1,
        ymax=0.65]
        \addplot table [x=k, y=LRWithPCA, col sep=semicolon] {figures/eurlex_3.csv};
        \addlegendentry{LRWithPCA}
        \addplot table [x=k, y=CPLST, col sep=semicolon] {figures/eurlex_3.csv};
        \addlegendentry{CPLST}
        \addplot table [x=k, y=LRWithRandomPCA, col sep=semicolon] {figures/eurlex_3.csv};
        \addlegendentry{LRWithRandomPCA}
        \addplot table [x=k, y=OCCA, col sep=semicolon] {figures/eurlex_3.csv};
        \addlegendentry{OCCA}
    \end{axis}
\end{tikzpicture}
\end{subfigure}


\end{figure}

\subsubsection{Bookmarks data set}

\begin{table}[H]
\centering
\caption{Accuracy of methods for bookmarks data set}
\label{tab:exp7}
\pgfplotstabletypeset [
    col sep=semicolon,
    columns/Method/.style={string type, column type={c|}},
    columns/Macro F1 score/.style={column type={c|}},
    columns/Micro F1 score/.style={column type={c|}},
    columns/Instance F1 score/.style={column type={c|}},
    columns/Hamming loss/.style={column type={c|}},
    every head row/.style={after row=\hline\hline}
]{figures/bookmarks.csv}
\end{table}

\begin{figure}[H]
%\centering
\caption{Relation between reduction degree and accuracy for bookmarks data set}
\label{fig:bookmarks}

\begin{subfigure}{.5\textwidth}
\caption{Hamming loss}
\label{fig:exp25}
\begin{tikzpicture}
    \begin{axis}[legend pos=north east,
        legend style={font=\fontsize{7}{5}\selectfont}, 
        xlabel={Degree of reduction},
        ylabel={Hamming loss},
        width=7cm,
        xmax=1,
        ymax=0.01]
        \addplot table [x=k, y=LRWithPCA, col sep=semicolon] {figures/bookmarks_0.csv};
        \addlegendentry{LRWithPCA}
        \addplot table [x=k, y=CPLST, col sep=semicolon] {figures/bookmarks_0.csv};
        \addlegendentry{CPLST}
        \addplot table [x=k, y=LRWithRandomPCA, col sep=semicolon] {figures/bookmarks_0.csv};
        \addlegendentry{LRWithRandomPCA}
        \addplot table [x=k, y=OCCA, col sep=semicolon] {figures/bookmarks_0.csv};
        \addlegendentry{OCCA}
        \addplot table [x=k, y=LR, col sep=semicolon] {figures/bookmarks_0.csv};
        \addlegendentry{LR}
    \end{axis}
\end{tikzpicture}
\end{subfigure}
\begin{subfigure}{.5\textwidth}
\caption{Macro F1 score}
\label{fig:exp26}
\begin{tikzpicture}
    \begin{axis}[legend pos=north east,
        legend style={font=\fontsize{7}{5}\selectfont}, 
        xlabel={Degree of reduction},
        ylabel={Macro F1 score},
        ylabel style={yshift=0.4cm},
        width=7cm,
        xmax=1,
        ymax=0.13]
        \addplot table [x=k, y=LRWithPCA, col sep=semicolon] {figures/bookmarks_1.csv};
        \addlegendentry{LRWithPCA}
        \addplot table [x=k, y=CPLST, col sep=semicolon] {figures/bookmarks_1.csv};
        \addlegendentry{CPLST}
        \addplot table [x=k, y=LRWithRandomPCA, col sep=semicolon] {figures/bookmarks_1.csv};
        \addlegendentry{LRWithRandomPCA}
        \addplot table [x=k, y=OCCA, col sep=semicolon] {figures/bookmarks_1.csv};
        \addlegendentry{OCCA}
        \addplot table [x=k, y=LR, col sep=semicolon] {figures/bookmarks_1.csv};
        \addlegendentry{LR}
    \end{axis}
\end{tikzpicture}
\end{subfigure}

\begin{subfigure}{.5\textwidth}
\caption{Micro F1 score}
\label{fig:exp27}
\begin{tikzpicture}
    \begin{axis}[legend pos=north east,
        legend style={font=\fontsize{7}{5}\selectfont}, 
        xlabel={Degree of reduction},
        ylabel={Micro F1 score},
        width=7cm,
        xmax=1,
        ymax=0.3]
        \addplot table [x=k, y=LRWithPCA, col sep=semicolon] {figures/bookmarks_2.csv};
        \addlegendentry{LRWithPCA}
        \addplot table [x=k, y=CPLST, col sep=semicolon] {figures/bookmarks_2.csv};
        \addlegendentry{CPLST}
        \addplot table [x=k, y=LRWithRandomPCA, col sep=semicolon] {figures/bookmarks_2.csv};
        \addlegendentry{LRWithRandomPCA}
        \addplot table [x=k, y=OCCA, col sep=semicolon] {figures/bookmarks_2.csv};
        \addlegendentry{OCCA}
        \addplot table [x=k, y=LR, col sep=semicolon] {figures/bookmarks_2.csv};
        \addlegendentry{LR}
    \end{axis}
\end{tikzpicture}
\end{subfigure}
\begin{subfigure}{.5\textwidth}
\caption{Instance F1 score}
\label{fig:exp28}
\begin{tikzpicture}
    \begin{axis}[legend pos=north east,
        legend style={font=\fontsize{7}{5}\selectfont},
        xlabel={Degree of reduction},
        ylabel={Instance F1 score},
        width=7cm,
        xmax=1,
        ymax=0.25]
        \addplot table [x=k, y=LRWithPCA, col sep=semicolon] {figures/bookmarks_3.csv};
        \addlegendentry{LRWithPCA}
        \addplot table [x=k, y=CPLST, col sep=semicolon] {figures/bookmarks_3.csv};
        \addlegendentry{CPLST}
        \addplot table [x=k, y=LRWithRandomPCA, col sep=semicolon] {figures/bookmarks_3.csv};
        \addlegendentry{LRWithRandomPCA}
        \addplot table [x=k, y=OCCA, col sep=semicolon] {figures/bookmarks_3.csv};
        \addlegendentry{OCCA}
        \addplot table [x=k, y=LR, col sep=semicolon] {figures/bookmarks_3.csv};
        \addlegendentry{LR}
    \end{axis}
\end{tikzpicture}
\end{subfigure}


\end{figure}

\newpage
\subsection{Comparison of methods efficiency}

The efficiency experiment aimed at measuring time of training classifier by particular methods and was performed on bookmarks data set with a changeable number of instances. The computation was run in single- and multi-threaded environment, in order to show how multithreading affects the efficiency. The test involved the following algorithms:
\begin{itemize}
    \item CPLST,
    \item LR,
    \item LRWithPCA,
    \item LRWithRPCA(L) which is linear regression with random PCA compression on a label space,
    \item LRWithRPCA(F) which is linear regression with random PCA compression on a feature space,
    \item OCCA.
\end{itemize}
Due to meaningful differences (even about an order of magnitude) between particular algorithms, the results are shown in three figures: \Crefrange{fig:exp29}{fig:exp31}.

\newpage
\subsubsection{Single-threaded performance}

\begin{figure}[H]
\centering
\caption{Efficiency of single-threaded LR and RPCA classifiers}
\label{fig:exp29}
\begin{tikzpicture}[scale=0.93]
    \begin{axis}[legend pos=north east,
        xlabel={number of instances},
        ylabel={time [s]},
        ymax={60}]
        \addplot table [x=instance, y=time, col sep=semicolon] {figures/LR1.csv};
        \addlegendentry{LR}
        \addplot table [x=instance, y=time, col sep=semicolon] {figures/LRWithRandomPCA1.csv};
        \addlegendentry{LRWithRPCA(L)}
        \addplot table [x=instance, y=time, col sep=semicolon] {figures/LRWithRandomPCA_d1.csv};
        \addlegendentry{LRWithRPCA(F)}

    \end{axis}
\end{tikzpicture}
\end{figure}

\begin{figure}[H]
\centering
\caption{Efficiency of single-threaded OCCA and CPLST}
\label{fig:exp30}
\begin{tikzpicture}[scale=0.93]
    \begin{axis}[legend pos=north east,
        xlabel={number of instances},
        ylabel={time [s]},
        ymax={1500}]
        \addplot table [x=instance, y=time, col sep=semicolon] {figures/CPLST1.csv};
        \addlegendentry{CPLST}
        \addplot table [x=instance, y=time, col sep=semicolon] {figures/OCCA1.csv};
        \addlegendentry{OCCA}

    \end{axis}
\end{tikzpicture}
\end{figure}

\begin{figure}[H]
\centering
\caption{Efficiency of single-threaded LRWithPCA}
\label{fig:exp31}
\begin{tikzpicture}[scale=0.93]
    \begin{axis}[legend pos=north east,
        xlabel={number of instances},
        ylabel={time [s]},
        ymax={5000}]
        \addplot table [x=instance, y=time, col sep=semicolon] {figures/LRWithPCA1.csv};
        \addlegendentry{LRWithPCA}

    \end{axis}
\end{tikzpicture}
\end{figure}

\subsubsection{Multi-threaded performance}

\begin{figure}[H]
\centering
\caption{Efficiency of multi-threaded LR and RPCA classifiers}
\label{fig:exp32}
\begin{tikzpicture}[scale=0.93]
    \begin{axis}[legend pos=north east,
        xlabel={number of instances},
        ylabel={time [s]},
        ymax=16]
        \addplot table [x=instance, y=time, col sep=semicolon] {figures/LR.csv};
        \addlegendentry{LR}
        \addplot table [x=instance, y=time, col sep=semicolon] {figures/LRWithRandomPCA.csv};
        \addlegendentry{LRWithRPCA(L)}
        \addplot table [x=instance, y=time, col sep=semicolon] {figures/LRWithRandomPCA_d.csv};
        \addlegendentry{LRWithRPCA(F)}

    \end{axis}
\end{tikzpicture}
\end{figure}

\begin{figure}[H]
\centering
\caption{Efficiency of multi-threaded OCCA and CPLST}
\label{fig:exp33}
\begin{tikzpicture}[scale=0.93]
    \begin{axis}[legend pos=north east,
        xlabel={number of instances},
        ylabel={time [s]},
        ymax=300]
        \addplot table [x=instance, y=time, col sep=semicolon] {figures/CPLST.csv};
        \addlegendentry{CPLST}
        \addplot table [x=instance, y=time, col sep=semicolon] {figures/OCCA.csv};
        \addlegendentry{OCCA}

    \end{axis}
\end{tikzpicture}
\end{figure}

\begin{figure}[H]
\centering
\caption{Efficiency of multi-threaded LRWithPCA}
\label{fig:exp34}
\begin{tikzpicture}[scale=0.93]
    \begin{axis}[legend pos=north east,
        xlabel={number of instances},
        ylabel={time [s]},
        ymax=2500]
        \addplot table [x=instance, y=time, col sep=semicolon] {figures/LRWithPCA.csv};
        \addlegendentry{LRWithPCA}
    \end{axis}
\end{tikzpicture}
\end{figure}
