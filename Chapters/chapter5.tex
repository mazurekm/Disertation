\chapter{Conclusion}

\section{Discussing quality experiment results}

The quality of classification for all the methods is strongly dependent on the training sets and the metric which is taken into account. The most 'difficult' training set is \textit{corel16k}, even though it is not the biggest set - its number of features, number of labels and number of instances as well are lower than in case of \textit{bookmarks} or \textit{EUR-Lex} data sets. Besides \textit{Hamming loss} metric, which is satisfying, the rest of them is levelled of $10^{-2}$ (\Cref{tab:exp5} and \Cref{fig:corel16k}) what is a very low score. As we see, a nature and a domain of data set also affect the results. On the other hand, the domain is not a dominant factor. \textit{Scene} data set, as well as \textit{corel16k}, is connected with images, but the results are far better for the first one (\Cref{tab:exp3}). It is worth mentioning that high scores were also reached for \textit{yeast} set - its domain is 'biology'.

The most effective approach, regardless of the metrics, is \textit{LR}. This is not certainly suprising - the rest of the methods use compression which causes a fall of values of the quality metrics. Among the algorithms which use compression, the best results were given by \textit{CPLST}. This is also rather predictible, because the reduction of a label space is feature awared unlike \textit{PCA} compression. Nevertheless, we should remember that all the approaches use a linear regressor to create a classifier. Thus, they behave rather similarly for particular datasets. For instance the characteristic features of all the methods are a low score of \textit{Macro-average F1} and a satisfying score of \textit{Hamming loss} for the majority of the datasets used in the experiment. 

\Crefrange{fig:enron}{fig:bookmarks} show the relation between a value of a reduction degree and a value of specific metrics. As we see the lower reduction degree we use, the worse scores we get in almost all cases. An interesting anomaly appears in \textit{EUR-Lex} dataset. In this particular case \textit{Hamming loss} increases regularly with a growth of a compression degree value. The situation is similar when it comes about \textit{Micro-average F1} (it should grow but it decreases). The domain of \textit{EUR-Lex} is 'text' - this set is connected with \textit{TF-IDF} representation of documents. It is possible that most of the features are useless and make noise in the data - it could explain the anomaly.  

\section{Discussing efficency experiment results}

All the methods, which took part in the experiment, perform faster in multithreaded environment. The difference is noticeable - for some algorithms a computation is even four times faster. It is certainly the result of efficient matrix operations (matrix multiplication etc.) which are suitable for parallelization. It is also obvious that time-consumption grows with a number of instances.

The best approach, when it comes about time-consumption, is \textit{LR} (\Cref{fig:exp29} and \Cref{fig:exp32}). Although the other methods create a classifier from compressed data, the time cost of such the transformation is too high. However, the results reached by \textit{LRWithRPCA} are not much worse than in case of \textit{LR}. Unlike the rest of the approaches based on preliminary compression, \textit{LRWithRPCA} doses not use \textit{SVD} decomposition for large matrices. This fact explains why this method is much faster - it is worth reminding that \textit{SVD} has the complexity of $O(m^2n+n^3)$. 

\Cref{fig:exp31,fig:exp34} show that the slowest approach is \textit{LRWithPCA}. We should remember that only a label space was compressed in the experiment - compressing a feature space was too time-consuming in case of \textit{LRWithPCA}. As we see, this implementation is useless for massive data. 

\textit{CPLST} and \textit{OCCA} (\Cref{fig:exp30,fig:exp33}) have almost the same time complexity. It is certainly not suprising - both the methods process matrices of the same size in the very similar way.

\section{Future research implications}

The efficency experiment has shown that parallelizing of computation has huge influence on time-consumption. Therefore it is sensible to implement the algorithms for environments which use GPU to process. This will probably improve the efficiency for all the methods. It is also worth checking if an involvement of greater amount of cores (threads) in processing decreases time-consumption.  

Among the tested algorithms there are two approaches which can be rejected: \textit{LRWithPCA} and \textit{OCCA}. The first one is definitely too slow and is also not satisfying when it comes about the quality. In fact, its random version gives similar quality results (sometimes even better). The second one is exactly as fast as \text{CPLST} algorithm, but reached worse scores in the quality experiment. 

The most suprising aspect of the research is the result achieved by \textit{LR} algorithm in both the experiments - especially in the second one. The transformations of feature and labels spaces have aimed at decreasing dimensions of input matrices for the linear regressor. Unfortunately these transformations are too time-consuming towards building the regressor. However, the time achieved by \textit{LRWithRPCA} is not much worse. Moreover it is possible to manipulate the specific parameters of this method what can help obtain better results. All in all, there is a lot to investigate in this approach.   

Even though \textit{CPLST} is not as efficient as \textit{LR} and \textit{LRWithRPCA}, this approach should also be studied - more generally, methods inspired by \textit{CCA} should be studied. Let us remind that the algorithm reached better results than the algorithms which use \textit{PCA} in the quality experiment. In this specific implementation of \textit{CPLST}, a linear regressor is used to build a final classifier - it is sensible to check different solutions, for example a logistic regressor etc. It is also sensible to check how some different regressor would cooperate with \textit{RandomPCA} algorithm.

\section{Summery}

The thesis aimed at investigating the algorithms which solve multi-label classification tasks by transformations of feature and label spaces. It is worth reminding that such the approach might cooperate well with \textit{binary relevance method}. Besides, we can additionally compress data what decreases the time complexity. 

The best scores were achieved by \textit{LR} classfier which does not use transformations. However, it does not mean the proposed approaches are useless. In fact, almost all the methods are fast and without compression they might be more accurate than \textit{LR}. It is significant to remeber, that such a good training time is the result of the calculations parallelizing which were possible by the fast linear algebra libraries. Let us also note that all the algorithms are not complicated. In fact, in the massive data era it is sensible to consider simpler models which can be effectively parallelized and improve them instead of developing sophisticated methods.

For the purposes of the experiments, the implementations of the algorithms were written in \textit{C++11} programming language and became a part of the library called \textit{MLCPACK}. It is an additional good point of the research. The library was organised in a flexible way (\textit{strategy} design pattern) and provides the interface which can be used to add new algorithms. Besides the algorithms, the library contains additional tools, such as \textit{ARFF} parser or quality evaluators. It is woth mentioning that \textit{MLCPACK} is prepared for performing in a multithreaded environment.
