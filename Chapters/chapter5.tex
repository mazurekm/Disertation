\chapter{Conclusion}

\section{Discussion of accuracy experiment results}

The accuracy of classification of all the methods is strongly dependent on the training sets and the metric which is taken into account. The most 'difficult' training set, for all the algorithms, is corel16k. Besides Hamming loss, which is satisfying, the rest of metrics is levelled of $10^{-2}$ (\Cref{tab:exp5} and \Cref{fig:corel16k}) what is a very low score. It is worth emphasizing that corel16k is the set of medium size, so it is hard to find a correlation between, for example, the number of labels and the accuracy. In fact, a nature and a domain of data set also affect the results. On the other hand, the domain is not a dominant factor. Scene data set, as well as corel16k, is connected with images, but the results are definitely better for scene (\Cref{tab:exp3}). It is worth mentioning that high scores were also achieved for yeast set - its domain is 'biology'.

The most effective approach, regardless of the metrics, is LR. This is not certainly something what we have expected, however this fact is explainable. We should remember that the rest of the methods use compression which might cause a fall of values of the accuracy. For these particular data sets, the reduction influences negatively the predictions. 

Among the algorithms which use compression, the best results were given by CPLST. This is certainly not surprising, because the reduction of a label space is feature aware unlike PCA compression. Nevertheless, all the approaches use a linear regressor to create a classifier. Thus, they behave rather similarly for particular data sets. For instance, the characteristic features of all the methods are a low score of Macro-average F1 and a satisfying score of Hamming loss. 

\Crefrange{fig:enron}{fig:bookmarks} show the relation between a value of a reduction degree and a value of specific metrics. As we see, the lower reduction degree we use, the worse scores we get in almost all cases. An interesting anomaly appears in EUR-Lex. In this particular case Hamming loss increases regularly with a growth of a compression degree value. The situation is similar when it comes to Micro-average F1 (it should grow but it decreases). The domain of EUR-Lex is 'text' and it contains \textit{TF-IDF} representation of documents. It is possible that most of the features are useless and make noise in the data. It could explain this anomaly.  

\section{Discussion of efficiency experiment results}

All the methods, which took part in the experiment, perform faster in multi-threaded environment. The difference is noticeable - for some algorithms a computation is even four times faster. It is certainly the result of efficient matrix operations (matrix multiplication etc.) which are suitable for parallelization. It is also obvious that time-consumption grows with a number of instances.

The best approach, when it comes to time-consumption, is again LR (\Cref{fig:exp29} and \Cref{fig:exp32}). Although the other methods create a classifier from compressed data, the time cost of such the transformation is too high. However, the results achieved by LRWithRPCA are not much worse than in case of LR. Unlike the rest of the approaches based on preliminary compression, LRWithRPCA does not use SVD decomposition for large matrices. This fact explains why this method is much faster. It is worth reminding that SVD has the complexity of $O(m^2n+n^3)$. 

\Cref{fig:exp31,fig:exp34} show that the slowest approach is LRWithPCA. We should remember that only a label space was compressed by PCA in the experiment, because compressing a feature space was too time-consuming. As we see, this implementation is useless for massive data. 

CPLST and OCCA (\Cref{fig:exp30,fig:exp33}) have almost the same time complexity. It is certainly not surprising, because both the methods process matrices of the same size in the very similar way.

\section{Future research implications}

The research was conducted with medium size data sets, so it is sensible to check how the algorithms deal with much greater sets. It will also allow verifying if simple and effective implementation of LR is better than the methods based on reduction of feature and label spaces. 

The efficiency experiment has shown that parallelizing of computation has huge influence on time-consumption. Therefore, it is sensible to implement the algorithms for environments which use GPU to process. This will probably improve the efficiency for all the methods. It is also worth checking if an involvement of higher amount of cores (threads) in performance decreases time-consumption.  

Among the tested algorithms there are two approaches which can be rejected: LRWithPCA and OCCA. The first one is definitely too slow and is also not satisfying when it comes to the accuracy. In fact, its random version gives similar accuracy results (sometimes even better). The second one is exactly as fast as CPLST algorithm, but achieved worse scores in the accuracy experiment. 

The most surprising aspect of the research is the result achieved by LR algorithm in both the experiments (especially in the second one). The reduction of feature and label spaces have aimed at decreasing dimensionallity of input data for linear regression. Unfortunately the reduction is too time-consuming towards building the regressor. However, the time achieved by LRWithRPCA is not much worse. Moreover it is possible to manipulate the parameters of this method what can help obtain better results. In fact, this approach can be constantly improving.   

Even though CPLST is not as efficient as LR and LRWithRPCA, this approach should also be studied (in general, methods inspired by CCA should be studied). Let us remind that the algorithm achieved better results than the algorithms which use PCA in the accuracy experiment. In this specific implementation of CPLST, a linear regressor is used to build a final classifier. Thus, it is sensible to check different solutions, for example how a logistic regressor will cooperate with CPLST etc.

\section{Summery}

The thesis aimed at investigating the algorithms which solve multi-label classification tasks by transformations of feature and label spaces. It is worth reminding that such approach might cooperate well with binary relevance method. Besides, we can additionally compress data what might also decrease the time complexity. 

The experiments showed that LR classifier is the fastest and the most accurate of all the tested methods. It means that there is no point in using complicated algorithms in order to learn from massive data. In fact, simple and fast implementation of linear regression is sufficient. However, it does not mean the proposed approaches are useless. We should remember that the experiments were conducted for particular class of data sets. We need to check how LR deals with much greater sets as well. Moreover, for data with noise, the reduction can be helpful because we can get rid of meaningless attributes. It is worth reminding that random PCA classifier was not much worse than LR, when it comes to efficiency. This approach can be constantly improved, so there is a lot to investigate.

For the purposes of the experiments, the implementations of the algorithms were written in C++11 programming language and became a part of the library called MLCPACK. It is an additional good point of the research. The library was organized in a flexible way (strategy design pattern) and provides the interface which can be used to add new algorithms. Besides the algorithms, the library contains additional tools, such as ARFF parser or a tool for measuring the predictive performance of the algorithms. It is worth mentioning that MLCPACK is prepared for performing in a multi-threaded environment.
