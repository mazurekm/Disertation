\chapter{Implementation}

\section{Requirements}

\subsection{General information}
All the methods, which have been discussed in this thesis, are a part of a library that can be used to solve multi-label classification problems in practice. The library was called \textit{MLCPACK}, which stands for \textit{Multi-Label Classification PACKage}. 

The \textit{API} was implemented in C++11 programming language and should be compiled by \textit{GCC ($>=$4.9)} in order to support all of new C++ features. The other compilers (\textit{Clang}, \textit{Visual C++ Compiler} etc.) have not been checked so far, so there is no warranty the build process succeeds in those cases.  The compilation process in managed by \textit{CMake} tool \citep{CMake} which is cross-platform and can be used in various operating systems. However, the library was tested only in \textit{Linux} environment (\textit{Debian 8.2}). 

Besides using the standard C++ library, there are also two external libraries which must be installed in a system: 

\begin{itemize}
    \item \textit{Boost ($>=$1.55)}
    \item \textit{Armadillo ($>=$6.100)}
\end{itemize}
The first one contains useful modules which extends possibilities of the standard library (unit tests, file system etc.), while Armadillo is an advanced linear algebra library which is discussed in the next section.  


\subsection{Efficiency of linear algebra library}

The efficiency of the algorithms, which are presented in Chapter 2, is strongly dependent on implementations of linear algebra operations such as pseudoinverse, SVD, etc. After analyzing available solutions, the API provided by Armadillo was chosen. Armadillo is high-quality library dedicated for C++ developers. The main strength of it is a good balance between a speed and ease of use. In fact, its syntax is similar to \textit{Matlab} environment. The example of source code is presented in \Cref{app:arma}.

Usage of Armadillo is simple, as it is shown in \Cref{app:arma}. However, the most important issue is a real speed of matrix operations. According to the documentation, the API is integrated with \textit{LAPACK} and \textit{BLAS} what means that effectiveness of matrix multiplication or its decomposition are dependent on these libraries (they are known as rather fast). There is also a possibility of linking \textit{OpenBLAS} instead of standard BLAS. \textit{OpenBLAS} supports multithreading. The number of threads, involved in computation, can be easily controlled by setting specific environment variables,\footnote{\bibentry{Blas}} i.e., \textit{OPENBLAS\_NUM\_THREADS}. In the implementation of MLCPACK, OpenBLAS library is used.    

\begin{figure}[h]
\centering
\caption{Efficiency of matrix multiplication.}
\label{fig:mulperf}
\begin{tikzpicture}
    \begin{axis}[legend pos=north east,
        xlabel={size of matrix},
        ylabel={time [s]},
        xmin=0,
        xmax=10500,
        ymin=0,
        ymax=200000,
        ymode=log]
        \addplot table [x=size, y=arma, col sep=semicolon] {figures/mul_test.csv};
        \addlegendentry{Armadillo}
        \addplot table [x=size, y=numpy, col sep=semicolon] {figures/mul_test.csv};
        \addlegendentry{NumPy}
    \end{axis}
\end{tikzpicture}
\end{figure}

\begin{figure}[h]
\centering
\caption{Efficiency of SVD decomposition.}
\label{fig:svdperf}
\begin{tikzpicture}
    \begin{axis}[legend pos=north east,
        xlabel={size of matrix},
        ylabel={time [s]},
        xmin=0,
        xmax=4500,
        ymin=0,
        ymax=650]
        \addplot table [x=size, y=arma, col sep=semicolon] {figures/svd_test.csv};
        \addlegendentry{Armadillo}
        \addplot table [x=size, y=numpy, col sep=semicolon] {figures/svd_test.csv};
        \addlegendentry{NumPy}
    \end{axis}
\end{tikzpicture}
\end{figure}


\Cref{fig:mulperf} and \Cref{fig:svdperf} show the speed of basic matrix operations performed by Armadillo and \textit{NumPy} which is an analogous linear algebra module for \textit{Python} programming language. As we see, Armadillo is definitely faster than NumPy for matrix multiplication and SVD as well.   
The experiment was run on the machine which has Intel Core i3-350M 2.26 GHz processor and 4096 MB of RAM. In case of Armadillo, the compilation of program was optimized (third level of optimization) and OpenBLAS was used instead of standard BLAS library. NumPy (1.8.2) was tested in \textit{Python3.4} environment (standard installation from Debian repository). Differences in time-consumption justify the choice of Armadillo and C++11 programming language.

\section{Structure of project}

MLCPACK consists of the two main modules:
\begin{itemize}
    \item \textit{Algorithms}
    \item \textit{Utils}
\end{itemize}

\subsection{Description of Algorithms module}

The Algorithms module contains all implementations of the algorithms discussed in this thesis. Its building is based on the \textit{Strategy} design pattern which is typical for specific family of algorithms. A client is allowed to simply rotate various methods. In other words, algorithms are replaced regardless of clients which use them. The structure of this module is shown in \Cref{fig:alg_sh}. 

The base class for the algorithm implementations is \textit{IStrategy}. The class contains two pure virtual methods: \textit{learn} and \textit{classify} which must be implemented. The second function takes an object of \textit{Instance} type as an argument which certainly wraps a particular instance and returns binary vector of labels. The constructor of IStrategy takes an only one argument of \textit{Instances} type which represents a training set. Let us notice that the \textit{LinearRegression} class, which inherits directly from IStrategy, is a base class for the rest of the methods. The regressor is an important component for all the approaches, therefore this relation is represented by an inheritance. In LinearRegression there are also two additional methods: \textit{save} and \textit{load} which take one argument of \textit{string} type. These functions are responsible for a serialization of a trained classifier. The idea is to store such classifier on hard drive and load it into memory if it is needed. It certainly allows saving time, especially if we take into account massive training sets. In contrast to IStrategy interface, LinearRegression class and its deriving classes have more complex constructors. They require an additional argument which is the regularization parameter. Moreover, the constructors of classes connected with algorithms based on the reduction of spaces need also the reduction degree parameter. The `learning flow' is presented in \Cref{app:learning}.

The Algorithms module also contains \textit{Evaluation} class which is used to evaluate particular methods. It allows measuring accuracy of classification by parameters, such as \textit{Micro-}, \textit{Instance-} and \textit{Macro-average of precision}, \textit{recall} and \textit{F1-score}. It also calculates \textit{Hamming loss} metric. The API is simple, as it is shown in \Cref{fig:alg_sh}. To construct the evaluator, we have to pass two arguments: a training set and a number of folds used for cross-validation. In order to start the whole process we certainly invoke the \textit{evaluate} method which takes a reference to the IStrategy object. The rest of the functions allow getting a specific accuracy metric. The `evaluating flow' is presented in \Cref{app:evaluating}.

\begin{figure}
\centering
\caption{UML diagram of Algorithms module.}
\label{fig:alg_sh}
\includegraphics[scale=0.5]{figures/mlcpack.png}
\end{figure}

\subsection{Description of Utils module}

The schema of the Utils module is shown in \Cref{fig:utils_sh}. The module contains classes which process and provide training data for IStrategy objects. The API was designed to support ARFF data format (the example of data written in this format is presented in \Cref{app:arff}), however there is a possibility to add different types of parsers. Each parser must inherit from the \textit{IParser} interface and implement two methods: \textit{parse} and \textit{getInstances}. The first method is certainly responsible for processing an input file, while the second method wraps parsed raw data by Instance and Instances objects. Let us notice that \textit{ArffParser} objects take an additional argument in its constructor. This second argument is a path to a file, in an \textit{XML} format, containing extra information which allows distinguishing which attributes are labels (\Cref{app:arff}).

Instance and Instances classes are used to simplify performing various operations on data. An object of Instance type wraps a single instance in a data set. As we see in \Cref{fig:utils_sh}, this class contains methods which allow writing (\textit{setAttributeValue}) or reading (\textit{getValueOfAttr}) a value of a specific attribute of an instance. An object of the Instances type is a collection of Instance objects. \textit{getAttributeMat} and \textit{getTargetsMat} methods of this class are used to generate a matrix of features and a matrix of labels wrapped by objects provided by Armadillo library. There is also a method \textit{shuffle} which changes randomly an order of instances.  

\begin{figure}
\centering
\caption{UML diagram of Utils module.}
\label{fig:utils_sh}
\includegraphics[scale=0.5]{figures/Utils.png}
\end{figure}

